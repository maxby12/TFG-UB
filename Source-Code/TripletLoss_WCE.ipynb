{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TripletLoss-WCE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNNjvvx1ig6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import gzip\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "!pip install umap-learn\n",
        "import umap\n",
        "\n",
        "!pip install spectral\n",
        "import spectral\n",
        "\n",
        "!pip install PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from six.moves import urllib\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.framework import dtypes\n",
        "#from tensorflow.contrib.tensorboard.plugins import projector\n",
        "from tensorflow.contrib.data.python.ops import sliding\n",
        "#from google.colab import files\n",
        "from skimage import io\n",
        "from matplotlib import pyplot as plt\n",
        "from decimal import Decimal\n",
        "from sklearn.cluster import KMeans\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
        "\n",
        "# RESNET IMPORTS\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "if not os.path.exists('./ngrok'):\n",
        "    !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "    !unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "plt.rcParams[\"axes.grid\"] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2lnPtaQbaIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)\n",
        "#!pip install tensorflow==1.13.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hWUKhLsAU9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up different folders for different runs of the model\n",
        "!rm -r sample_data\n",
        "#!rm -r './models'\n",
        "\n",
        "models_folder = './models'\n",
        "model_number = 0\n",
        "\n",
        "if not os.path.exists(models_folder):\n",
        "    os.makedirs(models_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBCslHGnPlgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TENSORBOARD LINK\n",
        "LOG_DIR = models_folder\n",
        "#LOG_DIR = \"resnet50_da_10h\"\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB-NdPdVbH7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UPLOAD TRAIN AND TEST TFRECORDS (only if needed)\n",
        "#uploaded = files.upload()\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Dataset drive ids and local filenames\n",
        "train_drive_ids = ['1OiU8q_CsJB9WOyNzXAAxv0t6Bpx-kDVq', '1NMkpf3UMmhHAt8BVSPFaLO7IOklDBVgA',\n",
        "                   '1G0TVFAJC-E34aUAnhyMp9Gwx75ib3IGK', '1EfBIf92wMQSNxnOi4YP6c0cbwFcTsocR',\n",
        "                   '1Z8jDG751km_oFU2I-5sjwaTE-hppuscC', '1mjKJRN0603mwZWd11B3AO-U-jsRVGzPN',\n",
        "                   '1VsqjRtRnFRqmcfiyrseCzhmKVgIlvoRP']\n",
        "train_files = ['Train-v'+str(count)+'.tfrecord' for count in range(len(train_drive_ids))]\n",
        "test_drive_id = '1QmisLIbdh4tTLboljGTx6b03vjFBsxUX'\n",
        "test_file = \"Test.tfrecord\"\n",
        "\n",
        "print(train_files)\n",
        "\n",
        "# Download files to local machine from drive\n",
        "for train_drive_id, train_file in zip(train_drive_ids, train_files):\n",
        "    train_download = drive.CreateFile({'id': train_drive_id})\n",
        "    train_download.GetContentFile(train_file)\n",
        "test_download = drive.CreateFile({'id': test_drive_id})\n",
        "test_download.GetContentFile(test_file)\n",
        "\n",
        "# Do the same but for SB3 classification tfrecords\n",
        "classification_train_id = '1bSKYCNfQkNZcgjWoAVxGZfXjqKc8Mnfu'\n",
        "classification_test_id = '1bC5MnG_Sr-Vds__jd1c-FVZfMSIaNc1r'\n",
        "classification_train = 'Classification-Train.tfrecord'\n",
        "classification_test = 'Classification-Test.tfrecord'\n",
        "\n",
        "train_download = drive.CreateFile({'id': classification_train_id})\n",
        "train_download.GetContentFile(classification_train)\n",
        "test_download = drive.CreateFile({'id': classification_test_id})\n",
        "test_download.GetContentFile(classification_test)\n",
        "\n",
        "# Do the same but for GFL classification tfrecords\n",
        "gfl_classification_train_id = '1jTWcgmqHL-zFKD4vK6uogryVs14aa43F'\n",
        "gfl_classification_test_id = '19dGvvmNuj8YxkYmJlkGH6ZSKSKwGk9wf'\n",
        "gfl_classification_train = 'GFL-Classification-Train.tfrecord'\n",
        "gfl_classification_test = 'GFL-Classification-Test.tfrecord'\n",
        "\n",
        "train_download = drive.CreateFile({'id': gfl_classification_train_id})\n",
        "train_download.GetContentFile(gfl_classification_train)\n",
        "test_download = drive.CreateFile({'id': gfl_classification_test_id})\n",
        "test_download.GetContentFile(gfl_classification_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYG93DjCnsU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download trained ResNet with ImageNet\n",
        "!rm -r resnet50_ImageNet\n",
        "trained_resnet_id = '1JhgNPbvJeSl7-VD4iXeDSDYCV_H5hw_K'\n",
        "trained_resnet_zip = 'resnet50_ImageNet.zip'\n",
        "resnet_download = drive.CreateFile({'id':trained_resnet_id})\n",
        "resnet_download.GetContentFile(trained_resnet_zip)\n",
        "!unzip resnet50_ImageNet.zip\n",
        "!rm resnet50_ImageNet.zip\n",
        "\n",
        "# Download trained ResNet NDA 20h\n",
        "!rm -r resnet50_nda_20h\n",
        "trained_resnet_id = '1ec4zPFVw1WRHHYz67TknM2qguFjOwwAt'\n",
        "trained_resnet_zip = 'resnet50_nda_20h.zip'\n",
        "resnet_download = drive.CreateFile({'id':trained_resnet_id})\n",
        "resnet_download.GetContentFile(trained_resnet_zip)\n",
        "!unzip resnet50_nda_20h.zip\n",
        "!rm resnet50_nda_20h.zip\n",
        "\n",
        "# Download trained ResNet DA 20h\n",
        "!rm -r resnet50_da_20h\n",
        "trained_resnet_id = '1PnUrlZuYVsuYFxcIeILV107x36XpgemC'\n",
        "trained_resnet_zip = 'resnet50_da_20h.zip'\n",
        "resnet_download = drive.CreateFile({'id':trained_resnet_id})\n",
        "resnet_download.GetContentFile(trained_resnet_zip)\n",
        "!unzip resnet50_da_20h.zip\n",
        "!rm resnet50_da_20h.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BojC3Ylxzuw",
        "colab_type": "text"
      },
      "source": [
        "# PARAMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCzn75SUpyxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARAMS (hyperparameters)\n",
        "\n",
        "# General params\n",
        "#######################################################\n",
        "num_epochs = -1 # 30 by default\n",
        "\n",
        "use_resnet_dense = True\n",
        "embedding_size = 2048 # only works when use_resnet_dense is True, otherwise embedding = 2048\n",
        "\n",
        "train_data_augmentation = True\n",
        "\n",
        "warm_dir = 'resnet50_da_20h'\n",
        "make_warm_start = True\n",
        "train_after_warm_start = False\n",
        "#######################################################\n",
        "\n",
        "batch_size = 64\n",
        "eval_batch_size = batch_size\n",
        "#random_batches = 10\n",
        "image_size = 256\n",
        "#train_size = 8389\n",
        "batch_shuffling_buffer_size = 600\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Technical params\n",
        "squared = False # euclidean distance norm squared?\n",
        "\n",
        "margin = 1.0 # margin distance between (a,p) and (a,n)\n",
        "triplet_strategy = 'batch_all_semihard_tf' # 'batch_all' (blog implementation not working?) - 'batch_all_semihard_tf' (tensorflow semihard batch all) - 'batch_hard' (batch hard blog implementation)\n",
        "\n",
        "# Save checkpoints during training params\n",
        "save_summary_steps = save_checkpoints_steps = 200\n",
        "min_secs_eval = 1.0\n",
        "\n",
        "# Early stopping param\n",
        "max_steps_without_decrease = 9999999\n",
        "run_every_steps = save_checkpoints_steps # Run validation every ? steps\n",
        "\n",
        "# Triplet loss params: abs(label1-label2) < tolerance ?\n",
        "label_frames_tolerance = 4\n",
        "\n",
        "# Features when reading Examples\n",
        "features = {\n",
        "    'rows': tf.FixedLenFeature([], tf.int64),\n",
        "    'cols': tf.FixedLenFeature([], tf.int64),\n",
        "    'channels': tf.FixedLenFeature([], tf.int64),\n",
        "    'image': tf.FixedLenFeature([], tf.string),\n",
        "    'label': tf.FixedLenFeature([], tf.int64)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMBT5E3XP4Fd",
        "colab_type": "text"
      },
      "source": [
        "# TFRECORD EXTRACTOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SnmEvfsVpBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLASS TO EXTRACT IMAGES FROM A TFRECORD AND RETURN IN A DATASET\n",
        "class TFRecordExtractor:\n",
        "    def __init__(self, tfrecord_file):\n",
        "        self.tfrecord_file = os.path.abspath(tfrecord_file)\n",
        "\n",
        "    def _extract_fn(self, tfrecord):\n",
        "        # Extract the data record\n",
        "        sample = tf.parse_single_example(tfrecord, features)\n",
        "\n",
        "        # cast image [0, 255] to [0.0, 1.0]\n",
        "        image = tf.image.decode_image(sample['image'], dtype=tf.uint8)\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        image = image / 255\n",
        "        img_shape = tf.stack([sample['rows'], sample['cols'], sample['channels']])\n",
        "        label = sample['label']\n",
        "        label = tf.cast(label, tf.int64)\n",
        "        #filename = sample['filename']\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "    def extract_image(self):\n",
        "\n",
        "        # Pipeline of dataset\n",
        "        dataset = tf.data.TFRecordDataset([self.tfrecord_file])\n",
        "        dataset = dataset.map(self._extract_fn)\n",
        "        \n",
        "        return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg4JEdIfP8UN",
        "colab_type": "text"
      },
      "source": [
        "# LOSSES AND SUPPORT FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlb2-Wq8jImJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Define functions to create the triplet loss with online triplet mining.\"\"\"\n",
        "\n",
        "def pairwise_distance(feature, squared=False):\n",
        "    \"\"\"Computes the pairwise distance matrix with numerical stability.\n",
        "    output[i, j] = || feature[i, :] - feature[j, :] ||_2\n",
        "    Args:\n",
        "      feature: 2-D Tensor of size [number of data, feature dimension].\n",
        "      squared: Boolean, whether or not to square the pairwise distances.\n",
        "    Returns:\n",
        "      pairwise_distances: 2-D Tensor of size [number of data, number of data].\n",
        "    \"\"\"\n",
        "    pairwise_distances_squared = math_ops.add(\n",
        "        math_ops.reduce_sum(math_ops.square(feature), axis=[1], keepdims=True),\n",
        "        math_ops.reduce_sum(\n",
        "            math_ops.square(array_ops.transpose(feature)),\n",
        "            axis=[0],\n",
        "            keepdims=True)) - 2.0 * math_ops.matmul(feature,\n",
        "                                                    array_ops.transpose(feature))\n",
        "\n",
        "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
        "    pairwise_distances_squared = math_ops.maximum(pairwise_distances_squared, 0.0)\n",
        "    # Get the mask where the zero distances are at.\n",
        "    error_mask = math_ops.less_equal(pairwise_distances_squared, 0.0)\n",
        "\n",
        "    # Optionally take the sqrt.\n",
        "    if squared:\n",
        "        pairwise_distances = pairwise_distances_squared\n",
        "    else:\n",
        "        pairwise_distances = math_ops.sqrt(\n",
        "          pairwise_distances_squared + math_ops.to_float(error_mask) * 1e-16)\n",
        "\n",
        "    # Undo conditionally adding 1e-16.\n",
        "    pairwise_distances = math_ops.multiply(\n",
        "        pairwise_distances, math_ops.to_float(math_ops.logical_not(error_mask)))\n",
        "\n",
        "    num_data = array_ops.shape(feature)[0]\n",
        "    # Explicitly set diagonals to zero.\n",
        "    mask_offdiagonals = array_ops.ones_like(pairwise_distances) - array_ops.diag(\n",
        "        array_ops.ones([num_data]))\n",
        "    pairwise_distances = math_ops.multiply(pairwise_distances, mask_offdiagonals)\n",
        "    return pairwise_distances\n",
        "\n",
        "\n",
        "def _get_anchor_positive_triplet_mask(labels):\n",
        "    \"\"\"Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
        "    Args:\n",
        "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
        "    Returns:\n",
        "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
        "    \"\"\"\n",
        "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
        "    indices_not_equal = tf.logical_not(indices_equal)\n",
        "\n",
        "    # Check if labels[i] == labels[j]\n",
        "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
        "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
        "\n",
        "    # Combine the two masks\n",
        "    mask = tf.logical_and(indices_not_equal, labels_equal)\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_anchor_negative_triplet_mask(labels):\n",
        "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
        "    Args:\n",
        "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
        "    Returns:\n",
        "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
        "    \"\"\"\n",
        "    # Check if labels[i] != labels[k]\n",
        "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
        "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
        "\n",
        "    mask = tf.logical_not(labels_equal)\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_triplet_mask(labels):\n",
        "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
        "    A triplet (i, j, k) is valid if:\n",
        "        - i, j, k are distinct\n",
        "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    Args:\n",
        "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
        "    \"\"\"\n",
        "    # Check that i, j and k are distinct\n",
        "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
        "    indices_not_equal = tf.logical_not(indices_equal)\n",
        "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
        "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
        "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
        "\n",
        "    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
        "\n",
        "\n",
        "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
        "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
        "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
        "\n",
        "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
        "\n",
        "    # Combine the two masks\n",
        "    mask = tf.logical_and(distinct_indices, valid_labels)\n",
        "\n",
        "    return mask\n",
        "\n",
        "def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):\n",
        "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
        "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
        "    Args:\n",
        "        labels: labels of the batch, of size (batch_size,)\n",
        "        embeddings: tensor of shape (batch_size, embed_dim)\n",
        "        margin: margin for triplet loss\n",
        "    Returns:\n",
        "        triplet_loss: scalar tensor containing the triplet loss\n",
        "    \"\"\"\n",
        "    # Get the pairwise distance matrix\n",
        "    pairwise_dist = pairwise_distances(embeddings, squared)\n",
        "\n",
        "    # For each anchor, get the hardest positive\n",
        "    # First, we need to get a mask for every valid positive (they should have same label)\n",
        "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
        "    mask_anchor_positive = tf.cast(mask_anchor_positive, tf.float32)\n",
        "\n",
        "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
        "    anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)\n",
        "\n",
        "    # shape (batch_size, 1)\n",
        "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
        "    tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
        "\n",
        "    # For each anchor, get the hardest negative\n",
        "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
        "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
        "    mask_anchor_negative = tf.cast(mask_anchor_negative, tf.float32)\n",
        "\n",
        "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
        "    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
        "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
        "\n",
        "    # shape (batch_size,)\n",
        "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
        "    tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
        "\n",
        "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
        "    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
        "\n",
        "    # Get final mean triplet loss\n",
        "    triplet_loss = tf.reduce_mean(triplet_loss)\n",
        "\n",
        "    return triplet_loss\n",
        "\n",
        "def batch_all_triplet_loss(labels, embeddings, margin, squared=False):\n",
        "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
        "    We generate all the valid triplets and average the loss over the positive ones.\n",
        "    Args:\n",
        "        labels: labels of the batch, of size (batch_size,)\n",
        "        embeddings: tensor of shape (batch_size, embed_dim)\n",
        "        margin: margin for triplet loss\n",
        "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
        "                 If false, output is the pairwise euclidean distance matrix.\n",
        "    Returns:\n",
        "        triplet_loss: scalar tensor containing the triplet loss\n",
        "    \"\"\"\n",
        "    # Get the pairwise distance matrix\n",
        "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
        "\n",
        "    # shape (batch_size, batch_size, 1)\n",
        "    anchor_positive_dist = tf.expand_dims(pairwise_dist, 2)\n",
        "    assert anchor_positive_dist.shape[2] == 1, \"{}\".format(anchor_positive_dist.shape)\n",
        "    # shape (batch_size, 1, batch_size)\n",
        "    anchor_negative_dist = tf.expand_dims(pairwise_dist, 1)\n",
        "    assert anchor_negative_dist.shape[1] == 1, \"{}\".format(anchor_negative_dist.shape)\n",
        "\n",
        "    # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
        "    # triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k\n",
        "    # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
        "    # and the 2nd (batch_size, 1, batch_size)\n",
        "    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin\n",
        "\n",
        "    # Put to zero the invalid triplets\n",
        "    # (where label(a) != label(p) or label(n) == label(a) or a == p)\n",
        "    mask = _get_triplet_mask(labels)\n",
        "    mask = tf.to_float(mask)\n",
        "    triplet_loss = tf.multiply(mask, triplet_loss)\n",
        "\n",
        "    # Remove negative losses (i.e. the easy triplets)\n",
        "    triplet_loss = tf.maximum(triplet_loss, 0.0)\n",
        "\n",
        "    # Count number of positive triplets (where triplet_loss > 0)\n",
        "    valid_triplets = tf.to_float(tf.greater(triplet_loss, 1e-16))\n",
        "    num_positive_triplets = tf.reduce_sum(valid_triplets)\n",
        "    num_valid_triplets = tf.reduce_sum(mask)\n",
        "    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets + 1e-16)\n",
        "\n",
        "    # Get final mean triplet loss over the positive valid triplets\n",
        "    triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + 1e-16)\n",
        "\n",
        "    return triplet_loss, fraction_positive_triplets\n",
        "\n",
        "def masked_minimum(data, mask, dim=1):\n",
        "    \"\"\"Computes the axis wise minimum over chosen elements.\n",
        "    Args:\n",
        "    data: 2-D float `Tensor` of size [n, m].\n",
        "    mask: 2-D Boolean `Tensor` of size [n, m].\n",
        "    dim: The dimension over which to compute the minimum.\n",
        "    Returns:\n",
        "    masked_minimums: N-D `Tensor`.\n",
        "      The minimized dimension is of size 1 after the operation.\n",
        "    \"\"\"\n",
        "    axis_maximums = math_ops.reduce_max(data, dim, keepdims=True)\n",
        "    masked_minimums = math_ops.reduce_min(\n",
        "      math_ops.multiply(data - axis_maximums, mask), dim,\n",
        "      keepdims=True) + axis_maximums\n",
        "    return masked_minimums\n",
        "\n",
        "def masked_maximum(data, mask, dim=1):\n",
        "    \"\"\"Computes the axis wise maximum over chosen elements.\n",
        "    Args:\n",
        "    data: 2-D float `Tensor` of size [n, m].\n",
        "    mask: 2-D Boolean `Tensor` of size [n, m].\n",
        "    dim: The dimension over which to compute the maximum.\n",
        "    Returns:\n",
        "    masked_maximums: N-D `Tensor`.\n",
        "      The maximized dimension is of size 1 after the operation.\n",
        "    \"\"\"\n",
        "    axis_minimums = math_ops.reduce_min(data, dim, keepdims=True)\n",
        "    masked_maximums = math_ops.reduce_max(\n",
        "      math_ops.multiply(data - axis_minimums, mask), dim,\n",
        "      keepdims=True) + axis_minimums\n",
        "    return masked_maximums\n",
        "\n",
        "def triplet_semihard_loss(labels, embeddings, margin=1.0):\n",
        "    \n",
        "    \"\"\"Computes the triplet loss with semi-hard negative mining.\n",
        "    The loss encourages the positive distances (between a pair of embeddings with\n",
        "    the same labels) to be smaller than the minimum negative distance among\n",
        "    which are at least greater than the positive distance plus the margin constant\n",
        "    (called semi-hard negative) in the mini-batch. If no such negative exists,\n",
        "    uses the largest negative distance instead.\n",
        "    See: https://arxiv.org/abs/1503.03832.\n",
        "    Args:\n",
        "    labels: 1-D tf.int32 `Tensor` with shape [batch_size] of\n",
        "      multiclass integer labels.\n",
        "    embeddings: 2-D float `Tensor` of embedding vectors. Embeddings should\n",
        "      be l2 normalized.\n",
        "    margin: Float, margin term in the loss definition.\n",
        "    Returns:\n",
        "    triplet_loss: tf.float32 scalar.\n",
        "    \"\"\"\n",
        "    # Reshape [batch_size] label tensor to a [batch_size, 1] label tensor.\n",
        "    lshape = array_ops.shape(labels)\n",
        "    assert lshape.shape == 1\n",
        "    labels = array_ops.reshape(labels, [lshape[0], 1])\n",
        "\n",
        "    # Build pairwise squared distance matrix.\n",
        "    pdist_matrix = pairwise_distance(embeddings, squared=squared)\n",
        "    \n",
        "    \n",
        "    # Build pairwise binary adjacency matrix.\n",
        "    #adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
        "    abs_label_distances = tf.cast(math_ops.abs(pairwise_distance( tf.cast(labels, tf.float32) )), tf.int64)\n",
        "    adjacency = math_ops.less(abs_label_distances, label_frames_tolerance)\n",
        "    \n",
        "    # Invert so we can select negatives only.\n",
        "    adjacency_not = math_ops.logical_not(adjacency)\n",
        "\n",
        "    batch_size = array_ops.size(labels)\n",
        "\n",
        "    # Compute the mask.\n",
        "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
        "    mask = math_ops.logical_and(\n",
        "      array_ops.tile(adjacency_not, [batch_size, 1]),\n",
        "      math_ops.greater(\n",
        "          pdist_matrix_tile, array_ops.reshape(\n",
        "              array_ops.transpose(pdist_matrix), [-1, 1])))\n",
        "    mask_final = array_ops.reshape(\n",
        "      math_ops.greater(\n",
        "          math_ops.reduce_sum(\n",
        "              math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
        "          0.0), [batch_size, batch_size])\n",
        "    mask_final = array_ops.transpose(mask_final)\n",
        "\n",
        "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
        "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
        "\n",
        "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
        "    negatives_outside = array_ops.reshape(\n",
        "      masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
        "    negatives_outside = array_ops.transpose(negatives_outside)\n",
        "\n",
        "    # negatives_inside: largest D_an.\n",
        "    negatives_inside = array_ops.tile(\n",
        "      masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
        "    semi_hard_negatives = array_ops.where(\n",
        "      mask_final, negatives_outside, negatives_inside)\n",
        "\n",
        "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
        "\n",
        "    mask_positives = math_ops.cast(\n",
        "      adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
        "          array_ops.ones([batch_size]))\n",
        "\n",
        "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
        "    #   in semihard, they take all positive pairs except the diagonal.\n",
        "    num_positives = math_ops.reduce_sum(mask_positives)\n",
        "\n",
        "    triplet_loss = math_ops.truediv(\n",
        "      math_ops.reduce_sum(\n",
        "          math_ops.maximum(\n",
        "              math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
        "      num_positives,\n",
        "      name='triplet_semihard_loss')\n",
        "\n",
        "    return triplet_loss, num_positives/( tf.cast(batch_size, tf.float32) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-Gif73RGjsz",
        "colab_type": "text"
      },
      "source": [
        "# KNN SCORE DEFINITIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzi3tBdlGiuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KNN(emb_dist, emb_index):\n",
        "    row = emb_dist[emb_index, :]\n",
        "    result = tf.nn.top_k(row, k=row.shape[0])\n",
        "    return tf.Session().run(result[0]), tf.Session().run(result[1])\n",
        "\n",
        "def show_KNN(images_set, emb_dist, i, rows, columns, figsize=25):\n",
        "    all_labels = images_set[:,1]\n",
        "    if i < 0: i = np.random.choice(all_labels, 1)\n",
        "    find, = np.where(all_labels == i)\n",
        "    most_k_similar = least_k_similar = rows*columns\n",
        "    \n",
        "    if len(find) <= 0:\n",
        "        print('Label selected is not in the test set!')\n",
        "        return\n",
        "    elif len(find) > 1:\n",
        "        print('More than 1 image found in the test set with the same label!')\n",
        "        #return\n",
        "    \n",
        "    i = find[0]\n",
        "    distances, index = KNN(emb_dist, i)\n",
        "\n",
        "    similar_index = index[-most_k_similar-1:-1]\n",
        "    similar_dist = distances[-most_k_similar-1:-1]\n",
        "    similar_index, similar_dist = np.flip(similar_index, 0), np.flip(similar_dist, 0)\n",
        "\n",
        "    least_index = index[:least_k_similar]\n",
        "    least_dist = distances[:least_k_similar]\n",
        "    \n",
        "    # SHOW MAIN IMAGE\n",
        "    f, axarr = plt.subplots(ncols=1, nrows=1, figsize=(5, 5))\n",
        "    img, label = images_set[i]\n",
        "    axarr.imshow(img)\n",
        "    axarr.set_title('Label: {}'.format(label), fontsize=20)\n",
        "    plt.show()\n",
        "    \n",
        "    # SHOW K SIMILAR IMAGES\n",
        "    print('\\nThe',most_k_similar,'most similar images:')\n",
        "    f, axarr = plt.subplots(ncols=columns, nrows=rows, figsize=(figsize, int(figsize/2)))\n",
        "    col = 0\n",
        "    row = 0\n",
        "    for j, dist in zip(similar_index, similar_dist):\n",
        "        img, label = images_set[j]\n",
        "        axarr[row, col].imshow(img)\n",
        "        axarr[row, col].set_title('L: {} - D: {:.3f}'.format(label, dist), fontsize=14)\n",
        "        col += 1\n",
        "        if col%columns==0:\n",
        "            row += 1\n",
        "            col = 0\n",
        "    plt.show()\n",
        "    \n",
        "    # SHOW K MOST DIFFERENT IMAGES\n",
        "    print('\\nThe',least_k_similar,'least similar images:')\n",
        "    f, axarr = plt.subplots(ncols=columns, nrows=rows, figsize=(figsize, int(figsize/2)))\n",
        "    col = 0\n",
        "    row = 0\n",
        "    for j, dist in zip(least_index, least_dist):\n",
        "        img, label = images_set[j]\n",
        "        axarr[row, col].imshow(img)\n",
        "        axarr[row, col].set_title('L: {} - D: {:.3f}'.format(label, dist), fontsize=14)\n",
        "        col += 1\n",
        "        if col%columns==0:\n",
        "            row += 1\n",
        "            col = 0\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mXFSfnDGoIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_KNN_score(emb_dist, all_labels=None, images_set=None, fracc=0.1):\n",
        "    print(\"Score based on the\",2*label_frames_tolerance,\"most similar frames for a given frame\")\n",
        "    \n",
        "    if fracc > 1.0: fracc = 1.0\n",
        "    if fracc <= 0.0: return 0, 0\n",
        "    if images_set is None and all_labels is None:\n",
        "        print(\"Cannot get the labels list\")\n",
        "        return\n",
        "    if all_labels is None:\n",
        "        all_labels = images_set[:,1]\n",
        "    \n",
        "    num_elements = int(fracc*len(all_labels))\n",
        "    num_elements = num_elements if num_elements > 0 else 1\n",
        "    \n",
        "    #print(\"num_elements:\",num_elements)\n",
        "    \n",
        "    step = int(len(all_labels) / num_elements)\n",
        "    \n",
        "    sum_score = 0\n",
        "    sum_dist = 0\n",
        "    for i in range(num_elements):\n",
        "        j = (i+1)*step\n",
        "        if j >= len(all_labels): break\n",
        "        \n",
        "        label = all_labels[j]\n",
        "        #if label < label_frames_tolerance or label > len(all_labels) - label_frames_tolerance: continue\n",
        "        \n",
        "        find, = np.where(all_labels == label)\n",
        "        if len(find) <= 0:\n",
        "            print('Label selected is not in the test set!')\n",
        "            continue\n",
        "        elif len(find) > 1:\n",
        "            print('More than 1 image found in the test set with the same label!')\n",
        "            continue\n",
        "        \n",
        "        j = find[0]\n",
        "        \n",
        "        distances = emb_dist[j, :]\n",
        "        index = np.argsort(distances)\n",
        "\n",
        "        similar_index = index[1:2*label_frames_tolerance + 1]\n",
        "        similar_labels = [all_labels[k] for k in similar_index]\n",
        "        positives = np.abs(similar_labels-label) < label_frames_tolerance\n",
        "        \n",
        "        sum_score += np.sum(positives)\n",
        "        sum_dist += np.sum( distances[similar_index] )\n",
        "        #print(np.sum(similar_dist) / (2*label_frames_tolerance))\n",
        "        #print(np.sum(positives))\n",
        "        #print(label)\n",
        "        #if i%50==0: print(i)\n",
        "        \n",
        "    return sum_score / (num_elements*2*label_frames_tolerance), sum_dist / (num_elements*2*label_frames_tolerance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8vk342UNiAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_simple_KNN_score(embeddings, all_labels, is_training):\n",
        "    #print(\"Score based on the\",2*label_frames_tolerance,\"most similar frames for a given frame\")\n",
        "    \n",
        "    if is_training: return (tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32))\n",
        "    \n",
        "    emb_dist = pairwise_distance(tf.math.l2_normalize(embeddings, axis=1), squared=squared)\n",
        "    \n",
        "    def index_to_label(index):\n",
        "        return tf.cond(tf.less(tf.cast(index, tf.int32), tf.cast(array_ops.size(all_labels), tf.int32) ), lambda: all_labels[index], lambda: all_labels[-1] ) \n",
        "    \n",
        "    def compute_label_values(row_distance, batch_size, label):\n",
        "        distances = tf.reshape(row_distance, [array_ops.size(row_distance)])\n",
        "        \n",
        "        index = tf.argsort(distances)\n",
        "        distances = tf.sort(distances)[1:2*label_frames_tolerance + 1]\n",
        "\n",
        "        similar_index = index[1:2*label_frames_tolerance + 1]\n",
        "        \n",
        "        similar_labels = tf.cast(tf.map_fn(index_to_label, similar_index, dtype=tf.int64), tf.int64)\n",
        "        positives = math_ops.less(math_ops.abs(math_ops.subtract(similar_labels, label )) , label_frames_tolerance)\n",
        "        \n",
        "        score = tf.reduce_sum( tf.cast(positives, tf.float32) )\n",
        "        dist = tf.reduce_sum( tf.cast(distances, tf.float32) )\n",
        "        \n",
        "        return score, dist\n",
        "    \n",
        "    def label_in_range(emb_dist, j, batch_size, label):\n",
        "        #return tf.cast(tf.shape(emb_dist)[0], tf.float32), tf.cast(tf.shape(emb_dist)[1], tf.float32)\n",
        "        j = tf.cast(j, tf.int32)\n",
        "        row_distance = tf.cond( tf.logical_and( tf.equal(batch_size, tf.cast(array_ops.shape(emb_dist)[1], tf.int64)), tf.less(j, tf.cast(tf.shape(emb_dist)[0], tf.int32) ) ), lambda: tf.slice(emb_dist, [j, 0], [1, tf.cast(tf.shape(emb_dist)[1],tf.int32)] ), lambda: tf.constant(np.empty(0), dtype=tf.float32) ) \n",
        "        return tf.cond(tf.equal(tf.size(row_distance), 0), lambda: (tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)) , lambda: compute_label_values(row_distance, batch_size, label))\n",
        "    \n",
        "    def compute_label(label):\n",
        "        \n",
        "        find = tf.where(tf.equal(all_labels, label))\n",
        "        j = find[0][0]\n",
        "        \n",
        "        batch_size = tf.cast(array_ops.shape(all_labels), tf.int64)[0]\n",
        "        #if batch_size: return tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)\n",
        "        \n",
        "        return tf.cond( tf.less(tf.cast(j, tf.int32), tf.shape(emb_dist)[0]), lambda: label_in_range(emb_dist, j, batch_size, label), lambda: (tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)) )\n",
        "\n",
        "        \n",
        "    #return tf.map_fn(compute_label, all_labels, dtype=(tf.float32, tf.float32))\n",
        "    \n",
        "    reduced_labels = tf.slice(all_labels, [tf.cast((tf.size(all_labels) / 2), tf.int32)], [1] )\n",
        "    sums = compute_label(reduced_labels)\n",
        "    #sums = tf.map_fn(compute_label, reduced_labels, dtype=(tf.float32, tf.float32))\n",
        "    score_mean = math_ops.truediv(math_ops.reduce_mean(sums[0]), tf.cast(2*label_frames_tolerance,tf.float32) , name='KNN_mean_score')\n",
        "    distance_mean = math_ops.truediv(math_ops.reduce_mean(sums[1]), tf.cast(2*label_frames_tolerance,tf.float32) , name=\"KNN_mean_distance\")\n",
        "    \n",
        "    return score_mean, distance_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwFITEELSux9",
        "colab_type": "text"
      },
      "source": [
        "# RANK SCORE DEFINITIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kut3jHpKO17_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rank_n_single_score(positives, n):\n",
        "    rank_range = positives[:n]\n",
        "    return 1 if np.sum(rank_range) > 0 else 0\n",
        "\n",
        "def rank_n_score(emb_dist, n, all_labels, num_elements):\n",
        "    step = int(len(all_labels) / num_elements)\n",
        "    sum_rank_n = 0\n",
        "    for i in range(num_elements):\n",
        "        j = (i+1)*step\n",
        "        if j >= len(all_labels): break\n",
        "        \n",
        "        label = all_labels[j]\n",
        "        #if label < label_frames_tolerance or label > len(all_labels) - label_frames_tolerance: continue\n",
        "        \n",
        "        find, = np.where(all_labels == label)\n",
        "        if len(find) <= 0:\n",
        "            print('Label selected is not in the test set!')\n",
        "            continue\n",
        "        elif len(find) > 1:\n",
        "            print('More than 1 image found in the test set with the same label!')\n",
        "            continue\n",
        "        \n",
        "        j = find[0]\n",
        "        \n",
        "        distances = emb_dist[j, :]\n",
        "        index = np.argsort(distances)\n",
        "\n",
        "        similar_index = index[1:2*label_frames_tolerance + 1]\n",
        "        similar_labels = [all_labels[k] for k in similar_index]\n",
        "        positives = np.abs(similar_labels-label) < label_frames_tolerance\n",
        "        \n",
        "        sum_rank_n += rank_n_single_score(positives, n)\n",
        "        #print(np.sum(positives))\n",
        "        #print(label)\n",
        "        #if i%50==0: print(i)\n",
        "        \n",
        "    return sum_rank_n / num_elements\n",
        "\n",
        "def rank_score_upto_n(N, emb_dist, all_labels=None, images_set=None, fracc=0.1):\n",
        "    if fracc > 1.0: fracc = 1.0\n",
        "    if fracc <= 0.0: return [0]*N\n",
        "    if images_set is None and all_labels is None:\n",
        "        print(\"Cannot get the labels list\")\n",
        "        return\n",
        "    if all_labels is None:\n",
        "        all_labels = images_set[:,1]\n",
        "    \n",
        "    num_elements = int(fracc*len(all_labels))\n",
        "    num_elements = num_elements if num_elements > 0 else 1\n",
        "    \n",
        "    print(\"Using\",num_elements,\"elements out of\", len(all_labels), \"for computing the rank scores\")\n",
        "    \n",
        "    rank_scores = []\n",
        "    for n in range(1, N+1):\n",
        "        #print(\"Computing rank\",n)\n",
        "        rank_scores.append( rank_n_score(emb_dist, n, all_labels, num_elements) )\n",
        "    return rank_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf3-jzIEQCC-",
        "colab_type": "text"
      },
      "source": [
        "# DATASET LOADING & INPUT_FN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiJegTkkQhnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rotate90(x: tf.Tensor, label):\n",
        "    \"\"\"Rotation augmentation\n",
        "    Args:\n",
        "        x: Image\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "\n",
        "    # Rotate 0, 90, 180, 270 degrees\n",
        "    return tf.image.rot90(x, 1), label\n",
        "\n",
        "def rotate180(x, label):\n",
        "    return tf.image.rot90(x, 2), label\n",
        "\n",
        "def rotate270(x, label):\n",
        "    return tf.image.rot90(x, 3), label\n",
        "\n",
        "def horizontal_flip(x: tf.Tensor, label):\n",
        "    \"\"\"Flip augmentation\n",
        "    Args:\n",
        "        x: Image to flip\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    return tf.image.flip_left_right(x), label\n",
        "\n",
        "def vertical_flip(x: tf.Tensor, label):\n",
        "    \"\"\"Flip augmentation\n",
        "    Args:\n",
        "        x: Image to flip\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    return tf.image.flip_up_down(x), label\n",
        "\n",
        "def all_data_augmentations(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.rot90(image, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "    return image, label\n",
        "\n",
        "def apply_data_augmentations(dataset):\n",
        "    \n",
        "    dataset = dataset.map(all_data_augmentations, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def concatenate_data_augmentations(dataset, ratio=0.7):\n",
        "    rot90 = dataset.map(lambda x,l: tf.cond(tf.random_uniform([], 0, 1) > 1-ratio, lambda: rotate90(x,l), lambda: (x,l)), num_parallel_calls=4)\n",
        "    rot180 = dataset.map(lambda x,l: tf.cond(tf.random_uniform([], 0, 1) > 1-ratio, lambda: rotate180(x,l), lambda: (x,l)), num_parallel_calls=4)\n",
        "    rot270 = dataset.map(lambda x,l: tf.cond(tf.random_uniform([], 0, 1) > 1-ratio, lambda: rotate270(x,l), lambda: (x,l)), num_parallel_calls=4)\n",
        "    hor_flip = dataset.map(lambda x,l: tf.cond(tf.random_uniform([], 0, 1) > 1-ratio, lambda: horizontal_flip(x,l), lambda: (x,l)), num_parallel_calls=4)\n",
        "    ver_flip = dataset.map(lambda x,l: tf.cond(tf.random_uniform([], 0, 1) > 1-ratio, lambda: vertical_flip(x,l), lambda: (x,l)), num_parallel_calls=4)\n",
        "    \n",
        "    dataset = dataset.concatenate(rot90)\n",
        "    dataset = dataset.concatenate(rot180)\n",
        "    dataset = dataset.concatenate(rot270)\n",
        "    dataset = dataset.concatenate(hor_flip)\n",
        "    dataset = dataset.concatenate(ver_flip)\n",
        "    \n",
        "    return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj3ZRdj2koI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(filePath):\n",
        "    t = TFRecordExtractor(filePath)\n",
        "    dataset = t.extract_image()\n",
        "    return dataset\n",
        "\n",
        "def load_multiple_datasets(paths):\n",
        "    final_dataset = None\n",
        "    for path in paths:\n",
        "        dataset = load_dataset(path)\n",
        "        final_dataset = final_dataset.concatenate(dataset) if final_dataset != None else dataset\n",
        "    return final_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRmy0EO1o-_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Create the input data pipeline using `tf.data`\"\"\"\n",
        "\n",
        "def train_input_fn_batch_shuffling(train_file):\n",
        "    if isinstance(train_file, list):\n",
        "        dataset = load_multiple_datasets(train_file)\n",
        "    else:\n",
        "        dataset = load_dataset(train_file)\n",
        "    \n",
        "    if train_data_augmentation:\n",
        "        dataset = apply_data_augmentations(dataset)\n",
        "    \n",
        "    dataset = dataset.batch(label_frames_tolerance)\n",
        "    dataset = dataset.shuffle(batch_shuffling_buffer_size)\n",
        "    dataset = dataset.apply(tf.data.experimental.unbatch())\n",
        "    if num_epochs >= 0: dataset = dataset.repeat(num_epochs)\n",
        "    else: dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(1)  # make sure you always have one batch ready to serve\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def train_input_fn(train_file):\n",
        "    if isinstance(train_file, list):\n",
        "        dataset = load_multiple_datasets(train_file)\n",
        "    else:\n",
        "        dataset = load_dataset(train_file)\n",
        "    \n",
        "    if train_data_augmentation:\n",
        "        dataset = apply_data_augmentations(dataset)\n",
        "        \n",
        "    \n",
        "    dataset = dataset.shuffle(int(1.2*batch_size))\n",
        "    if num_epochs >= 0: dataset = dataset.repeat(num_epochs)\n",
        "    else: dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(1)  # make sure you always have one batch ready to serve\n",
        "    return train_dataset\n",
        "\n",
        "def eval_input_fn(test_file):\n",
        "    dataset = load_dataset(test_file)\n",
        "    #dataset = dataset.repeat()  # indefinitely repeat\n",
        "    dataset = dataset.batch(eval_batch_size)\n",
        "    dataset = dataset.take(1)\n",
        "    dataset = dataset.prefetch(1)  # make sure you always have one batch ready to serve\n",
        "    return dataset\n",
        "\n",
        "def test_input_fn(test_file):\n",
        "    dataset = load_dataset(test_file)\n",
        "    #dataset = dataset.repeat()  # indefinitely repeat\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.shuffle(random_batches)\n",
        "    dataset = dataset.prefetch(1)  # make sure you always have one batch ready to serve\n",
        "    return dataset\n",
        "\n",
        "def load_knn_dataset(file):\n",
        "    dataset = load_dataset(file)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    #to_take = int(samples_for_scores/batch_size) + 1\n",
        "    #dataset = dataset.take(to_take)\n",
        "    dataset = dataset.prefetch(1)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97J7KiwP5jmg",
        "colab_type": "text"
      },
      "source": [
        "# RESNET MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv_A60mx97Uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SENSETHEFLOW NEEDED DEFINITIONS\n",
        "\n",
        "def detect_data_format():\n",
        "    return 'channels_first' if tf.test.is_built_with_cuda() else 'channels_last'\n",
        "\n",
        "def is_channels_first(data_format):\n",
        "    data_format = data_format.lower()\n",
        "    return data_format in ('channels_first', 'nchw')\n",
        "    \n",
        "def to_data_format(tensor, current_data_format, target_data_format):\n",
        "    if current_data_format == target_data_format:\n",
        "        return tensor\n",
        "    \n",
        "    if is_channels_first(target_data_format):\n",
        "        return tf.transpose(tensor, perm=[0, 3, 1, 2])\n",
        "    \n",
        "    return tf.transpose(tensor, perm=[0, 2, 3, 1])\n",
        "\n",
        "def channel_dim(data_format):\n",
        "    if is_channels_first(data_format):\n",
        "        return 1\n",
        "    return 3\n",
        "\n",
        "def wh_dims(data_format):\n",
        "    if is_channels_first(data_format):\n",
        "        return (2, 3)\n",
        "    return (1, 2)\n",
        "\n",
        "def channel_axis(f, data_format, *args, **kwargs):\n",
        "    return f(*args, axis=channel_dim(data_format), **kwargs)\n",
        "\n",
        "def _shape(shape, dim):\n",
        "    if isinstance(dim, (list, tuple)):\n",
        "        return shape[dim[0]:dim[1]+1]\n",
        "    return shape[dim]\n",
        "\n",
        "def static_shape(tensor, dims):\n",
        "    return _shape(tensor.shape.as_list(), dims)\n",
        "\n",
        "def tensor_shape(tensor, dims):\n",
        "    return _shape(tf.shape(tensor), dims)\n",
        "\n",
        "def image_resize(inputs, size, data_format, method=0):\n",
        "    inputs = to_data_format(inputs, data_format, 'channels_last')        \n",
        "    inputs = tf.image.resize_images(inputs, size, method=method)\n",
        "    inputs = to_data_format(inputs, 'channels_last', data_format)\n",
        "    return inputs\n",
        "\n",
        "def norm(x, norm_type, is_training, data_format, G=32, esp=1e-5, momentum=0.999, epsilon=1e-5):\n",
        "    if norm_type == 'none':\n",
        "        output = x\n",
        "    elif norm_type == 'batch':\n",
        "        output = tf.layers.batch_normalization(\n",
        "            x, center=True, scale=True, momentum=momentum,\n",
        "            epsilon=epsilon, fused=True, axis=channel_dim(data_format),\n",
        "            training=is_training)\n",
        "    elif norm_type == 'group':\n",
        "        output = GroupNorm(G, esp, data_format)(x)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0-NVQ4E5lcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Contains definitions for Residual Networks.\n",
        "\n",
        "Residual networks ('v1' ResNets) were originally proposed in:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "\n",
        "The full preactivation 'v2' ResNet variant was introduced by:\n",
        "[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Identity Mappings in Deep Residual Networks. arXiv: 1603.05027\n",
        "\n",
        "The key difference of the full preactivation 'v2' variant compared to the\n",
        "'v1' variant in [1] is the use of batch normalization before every weight layer\n",
        "rather than after.\n",
        "\"\"\"\n",
        "\n",
        "_BATCH_NORM_DECAY = 0.997\n",
        "_BATCH_NORM_EPSILON = 1e-5\n",
        "DEFAULT_VERSION = 2\n",
        "DEFAULT_DTYPE = tf.float32\n",
        "CASTABLE_TYPES = (tf.float16,)\n",
        "ALLOWED_TYPES = (DEFAULT_DTYPE,) + CASTABLE_TYPES\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Convenience functions for building the ResNet model.\n",
        "################################################################################\n",
        "def batch_norm(inputs, training, data_format, norm_type):\n",
        "  \"\"\"Performs a batch normalization using a standard set of parameters.\"\"\"\n",
        "  # We set fused=True for a significant performance boost. See\n",
        "  # https://www.tensorflow.org/performance/performance_guide#common_fused_ops\n",
        "  return norm(inputs, norm_type, training, data_format, momentum=_BATCH_NORM_DECAY,\n",
        "          epsilon=_BATCH_NORM_EPSILON)\n",
        "  #return tf.layers.batch_normalization(\n",
        "  #    inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
        "  #    momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n",
        "  #    scale=True, training=training, fused=True)\n",
        "\n",
        "\n",
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "  \"\"\"Pads the input along the spatial dimensions independently of input size.\n",
        "\n",
        "  Args:\n",
        "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
        "      [batch, height_in, width_in, channels] depending on data_format.\n",
        "    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
        "                 Should be a positive integer.\n",
        "    data_format: The input format ('channels_last' or 'channels_first').\n",
        "\n",
        "  Returns:\n",
        "    A tensor with the same format as the input with the data either intact\n",
        "    (if kernel_size == 1) or padded (if kernel_size > 1).\n",
        "  \"\"\"\n",
        "  pad_total = kernel_size - 1\n",
        "  pad_beg = pad_total // 2\n",
        "  pad_end = pad_total - pad_beg\n",
        "\n",
        "  if data_format == 'channels_first':\n",
        "    padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
        "                                    [pad_beg, pad_end], [pad_beg, pad_end]])\n",
        "  else:\n",
        "    padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
        "                                    [pad_beg, pad_end], [0, 0]])\n",
        "  return padded_inputs\n",
        "\n",
        "\n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, strides, data_format):\n",
        "  \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n",
        "  # The padding is consistent and is based only on `kernel_size`, not on the\n",
        "  # dimensions of `inputs` (as opposed to using `tf.layers.conv2d` alone).\n",
        "  if strides > 1:\n",
        "    inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "\n",
        "  return tf.layers.conv2d(\n",
        "      inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,\n",
        "      padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,\n",
        "      kernel_initializer=tf.variance_scaling_initializer(),\n",
        "      data_format=data_format)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# ResNet block definitions.\n",
        "################################################################################\n",
        "def _building_block_v1(inputs, filters, training, projection_shortcut, strides,\n",
        "                       data_format, norm_type):\n",
        "  \"\"\"A single block for ResNet v1, without a bottleneck.\n",
        "\n",
        "  Convolution then batch normalization then ReLU as described by:\n",
        "    Deep Residual Learning for Image Recognition\n",
        "    https://arxiv.org/pdf/1512.03385.pdf\n",
        "    by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.\n",
        "\n",
        "  Args:\n",
        "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
        "      [batch, height_in, width_in, channels] depending on data_format.\n",
        "    filters: The number of filters for the convolutions.\n",
        "    training: A Boolean for whether the model is in training or inference\n",
        "      mode. Needed for batch normalization.\n",
        "    projection_shortcut: The function to use for projection shortcuts\n",
        "      (typically a 1x1 convolution when downsampling the input).\n",
        "    strides: The block's stride. If greater than 1, this block will ultimately\n",
        "      downsample the input.\n",
        "    data_format: The input format ('channels_last' or 'channels_first').\n",
        "\n",
        "  Returns:\n",
        "    The output tensor of the block; shape should match inputs.\n",
        "  \"\"\"\n",
        "  shortcut = inputs\n",
        "\n",
        "  if projection_shortcut is not None:\n",
        "    shortcut = projection_shortcut(inputs)\n",
        "    shortcut = batch_norm(inputs=shortcut, training=training,\n",
        "                          data_format=data_format, norm_type=norm_type)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=1,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs += shortcut\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  return inputs\n",
        "\n",
        "\n",
        "def _building_block_v2(inputs, filters, training, projection_shortcut, strides,\n",
        "                       data_format, norm_type):\n",
        "  \"\"\"A single block for ResNet v2, without a bottleneck.\n",
        "\n",
        "  Batch normalization then ReLu then convolution as described by:\n",
        "    Identity Mappings in Deep Residual Networks\n",
        "    https://arxiv.org/pdf/1603.05027.pdf\n",
        "    by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.\n",
        "\n",
        "  Args:\n",
        "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
        "      [batch, height_in, width_in, channels] depending on data_format.\n",
        "    filters: The number of filters for the convolutions.\n",
        "    training: A Boolean for whether the model is in training or inference\n",
        "      mode. Needed for batch normalization.\n",
        "    projection_shortcut: The function to use for projection shortcuts\n",
        "      (typically a 1x1 convolution when downsampling the input).\n",
        "    strides: The block's stride. If greater than 1, this block will ultimately\n",
        "      downsample the input.\n",
        "    data_format: The input format ('channels_last' or 'channels_first').\n",
        "\n",
        "  Returns:\n",
        "    The output tensor of the block; shape should match inputs.\n",
        "  \"\"\"\n",
        "  shortcut = inputs\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  # The projection shortcut should come after the first batch norm and ReLU\n",
        "  # since it performs a 1x1 convolution.\n",
        "  if projection_shortcut is not None:\n",
        "    shortcut = projection_shortcut(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=1,\n",
        "      data_format=data_format)\n",
        "\n",
        "  return inputs + shortcut\n",
        "\n",
        "\n",
        "def _bottleneck_block_v1(inputs, filters, training, projection_shortcut,\n",
        "                         strides, data_format, norm_type):\n",
        "  \"\"\"A single block for ResNet v1, with a bottleneck.\n",
        "\n",
        "  Similar to _building_block_v1(), except using the \"bottleneck\" blocks\n",
        "  described in:\n",
        "    Convolution then batch normalization then ReLU as described by:\n",
        "      Deep Residual Learning for Image Recognition\n",
        "      https://arxiv.org/pdf/1512.03385.pdf\n",
        "      by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.\n",
        "\n",
        "  Args:\n",
        "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
        "      [batch, height_in, width_in, channels] depending on data_format.\n",
        "    filters: The number of filters for the convolutions.\n",
        "    training: A Boolean for whether the model is in training or inference\n",
        "      mode. Needed for batch normalization.\n",
        "    projection_shortcut: The function to use for projection shortcuts\n",
        "      (typically a 1x1 convolution when downsampling the input).\n",
        "    strides: The block's stride. If greater than 1, this block will ultimately\n",
        "      downsample the input.\n",
        "    data_format: The input format ('channels_last' or 'channels_first').\n",
        "\n",
        "  Returns:\n",
        "    The output tensor of the block; shape should match inputs.\n",
        "  \"\"\"\n",
        "  shortcut = inputs\n",
        "\n",
        "  if projection_shortcut is not None:\n",
        "    shortcut = projection_shortcut(inputs)\n",
        "    shortcut = batch_norm(inputs=shortcut, training=training,\n",
        "                          data_format=data_format, norm_type=norm_type)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs += shortcut\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  return inputs\n",
        "\n",
        "\n",
        "def _bottleneck_block_v2(inputs, filters, training, projection_shortcut,\n",
        "                         strides, data_format, norm_type):\n",
        "  \"\"\"A single block for ResNet v2, with a bottleneck.\n",
        "\n",
        "  Similar to _building_block_v2(), except using the \"bottleneck\" blocks\n",
        "  described in:\n",
        "    Convolution then batch normalization then ReLU as described by:\n",
        "      Deep Residual Learning for Image Recognition\n",
        "      https://arxiv.org/pdf/1512.03385.pdf\n",
        "      by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.\n",
        "\n",
        "  Adapted to the ordering conventions of:\n",
        "    Batch normalization then ReLu then convolution as described by:\n",
        "      Identity Mappings in Deep Residual Networks\n",
        "      https://arxiv.org/pdf/1603.05027.pdf\n",
        "      by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.\n",
        "\n",
        "  Args:\n",
        "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
        "      [batch, height_in, width_in, channels] depending on data_format.\n",
        "    filters: The number of filters for the convolutions.\n",
        "    training: A Boolean for whether the model is in training or inference\n",
        "      mode. Needed for batch normalization.\n",
        "    projection_shortcut: The function to use for projection shortcuts\n",
        "      (typically a 1x1 convolution when downsampling the input).\n",
        "    strides: The block's stride. If greater than 1, this block will ultimately\n",
        "      downsample the input.\n",
        "    data_format: The input format ('channels_last' or 'channels_first').\n",
        "\n",
        "  Returns:\n",
        "    The output tensor of the block; shape should match inputs.\n",
        "  \"\"\"\n",
        "  shortcut = inputs\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "\n",
        "  # The projection shortcut should come after the first batch norm and ReLU\n",
        "  # since it performs a 1x1 convolution.\n",
        "  if projection_shortcut is not None:\n",
        "    shortcut = projection_shortcut(inputs)\n",
        "\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=filters, kernel_size=3, strides=strides,\n",
        "      data_format=data_format)\n",
        "\n",
        "  inputs = batch_norm(inputs, training, data_format, norm_type)\n",
        "  inputs = tf.nn.relu(inputs)\n",
        "  inputs = conv2d_fixed_padding(\n",
        "      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,\n",
        "      data_format=data_format)\n",
        "\n",
        "  return inputs + shortcut\n",
        "\n",
        "\n",
        "def block_layer(inputs, filters, bottleneck, block_fn, blocks, strides,\n",
        "                training, name, data_format, norm_type):\n",
        "  \"\"\"Creates one layer of blocks for the ResNet model.\n",
        "\n",
        "  Args:\n",
        "    inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
        "      [batch, height_in, width_in, channels] depending on data_format.\n",
        "    filters: The number of filters for the first convolution of the layer.\n",
        "    bottleneck: Is the block created a bottleneck block.\n",
        "    block_fn: The block to use within the model, either `building_block` or\n",
        "      `bottleneck_block`.\n",
        "    blocks: The number of blocks contained in the layer.\n",
        "    strides: The stride to use for the first convolution of the layer. If\n",
        "      greater than 1, this layer will ultimately downsample the input.\n",
        "    training: Either True or False, whether we are currently training the\n",
        "      model. Needed for batch norm.\n",
        "    name: A string name for the tensor output of the block layer.\n",
        "    data_format: The input format ('channels_last' or 'channels_first').\n",
        "\n",
        "  Returns:\n",
        "    The output tensor of the block layer.\n",
        "  \"\"\"\n",
        "\n",
        "  # Bottleneck blocks end with 4x the number of filters as they start with\n",
        "  filters_out = filters * 4 if bottleneck else filters\n",
        "\n",
        "  def projection_shortcut(inputs):\n",
        "    return conv2d_fixed_padding(\n",
        "        inputs=inputs, filters=filters_out, kernel_size=1, strides=strides,\n",
        "        data_format=data_format)\n",
        "\n",
        "  # Only the first block per block_layer uses projection_shortcut and strides\n",
        "  inputs = block_fn(inputs, filters, training, projection_shortcut, strides,\n",
        "                    data_format, norm_type)\n",
        "\n",
        "  for _ in range(1, blocks):\n",
        "    inputs = block_fn(inputs, filters, training, None, 1, data_format, norm_type)\n",
        "\n",
        "  return tf.identity(inputs, name)\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "  \"\"\"Base class for building the Resnet Model.\"\"\"\n",
        "\n",
        "  def __init__(self, resnet_size, bottleneck, num_classes, num_filters,\n",
        "               kernel_size,\n",
        "               conv_stride, first_pool_size, first_pool_stride,\n",
        "               block_sizes, block_strides,\n",
        "               final_size, norm_type='batch', skip_dense=False, skip_reduction = False, \n",
        "               resnet_version=DEFAULT_VERSION, data_format=None,\n",
        "               dtype=DEFAULT_DTYPE):\n",
        "    \"\"\"Creates a model for classifying an image.\n",
        "\n",
        "    Args:\n",
        "      resnet_size: A single integer for the size of the ResNet model.\n",
        "      bottleneck: Use regular blocks or bottleneck blocks.\n",
        "      num_classes: The number of classes used as labels.\n",
        "      num_filters: The number of filters to use for the first block layer\n",
        "        of the model. This number is then doubled for each subsequent block\n",
        "        layer.\n",
        "      kernel_size: The kernel size to use for convolution.\n",
        "      conv_stride: stride size for the initial convolutional layer\n",
        "      first_pool_size: Pool size to be used for the first pooling layer.\n",
        "        If none, the first pooling layer is skipped.\n",
        "      first_pool_stride: stride size for the first pooling layer. Not used\n",
        "        if first_pool_size is None.\n",
        "      block_sizes: A list containing n values, where n is the number of sets of\n",
        "        block layers desired. Each value should be the number of blocks in the\n",
        "        i-th set.\n",
        "      block_strides: List of integers representing the desired stride size for\n",
        "        each of the sets of block layers. Should be same length as block_sizes.\n",
        "      final_size: The expected size of the model after the second pooling.\n",
        "      resnet_version: Integer representing which version of the ResNet network\n",
        "        to use. See README for details. Valid values: [1, 2]\n",
        "      data_format: Input format ('channels_last', 'channels_first', or None).\n",
        "        If set to None, the format is dependent on whether a GPU is available.\n",
        "      dtype: The TensorFlow dtype to use for calculations. If not specified\n",
        "        tf.float32 is used.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: if invalid version is selected.\n",
        "    \"\"\"\n",
        "    self.resnet_size = resnet_size\n",
        "\n",
        "    if not data_format:\n",
        "      data_format = (\n",
        "          'channels_first' if tf.test.is_built_with_cuda() else 'channels_last')\n",
        "\n",
        "    self.resnet_version = resnet_version\n",
        "    if resnet_version not in (1, 2):\n",
        "      raise ValueError(\n",
        "          'Resnet version should be 1 or 2. See README for citations.')\n",
        "\n",
        "    self.bottleneck = bottleneck\n",
        "    if bottleneck:\n",
        "      if resnet_version == 1:\n",
        "        self.block_fn = _bottleneck_block_v1\n",
        "      else:\n",
        "        self.block_fn = _bottleneck_block_v2\n",
        "    else:\n",
        "      if resnet_version == 1:\n",
        "        self.block_fn = _building_block_v1\n",
        "      else:\n",
        "        self.block_fn = _building_block_v2\n",
        "\n",
        "    if dtype not in ALLOWED_TYPES:\n",
        "      raise ValueError('dtype must be one of: {}'.format(ALLOWED_TYPES))\n",
        "\n",
        "    self.data_format = data_format\n",
        "    self.num_classes = num_classes\n",
        "    self.num_filters = num_filters\n",
        "    self.kernel_size = kernel_size\n",
        "    self.conv_stride = conv_stride\n",
        "    self.first_pool_size = first_pool_size\n",
        "    self.first_pool_stride = first_pool_stride\n",
        "    self.block_sizes = block_sizes\n",
        "    self.block_strides = block_strides\n",
        "    self.final_size = final_size\n",
        "    self.dtype = dtype\n",
        "    self.pre_activation = resnet_version == 2\n",
        "    self.norm_type = norm_type\n",
        "    self.skip_dense = skip_dense\n",
        "    self.skip_reduction = skip_reduction\n",
        "\n",
        "  def _custom_dtype_getter(self, getter, name, shape=None, dtype=DEFAULT_DTYPE,\n",
        "                           *args, **kwargs):\n",
        "    \"\"\"Creates variables in fp32, then casts to fp16 if necessary.\n",
        "\n",
        "    This function is a custom getter. A custom getter is a function with the\n",
        "    same signature as tf.get_variable, except it has an additional getter\n",
        "    parameter. Custom getters can be passed as the `custom_getter` parameter of\n",
        "    tf.variable_scope. Then, tf.get_variable will call the custom getter,\n",
        "    instead of directly getting a variable itself. This can be used to change\n",
        "    the types of variables that are retrieved with tf.get_variable.\n",
        "    The `getter` parameter is the underlying variable getter, that would have\n",
        "    been called if no custom getter was used. Custom getters typically get a\n",
        "    variable with `getter`, then modify it in some way.\n",
        "\n",
        "    This custom getter will create an fp32 variable. If a low precision\n",
        "    (e.g. float16) variable was requested it will then cast the variable to the\n",
        "    requested dtype. The reason we do not directly create variables in low\n",
        "    precision dtypes is that applying small gradients to such variables may\n",
        "    cause the variable not to change.\n",
        "\n",
        "    Args:\n",
        "      getter: The underlying variable getter, that has the same signature as\n",
        "        tf.get_variable and returns a variable.\n",
        "      name: The name of the variable to get.\n",
        "      shape: The shape of the variable to get.\n",
        "      dtype: The dtype of the variable to get. Note that if this is a low\n",
        "        precision dtype, the variable will be created as a tf.float32 variable,\n",
        "        then cast to the appropriate dtype\n",
        "      *args: Additional arguments to pass unmodified to getter.\n",
        "      **kwargs: Additional keyword arguments to pass unmodified to getter.\n",
        "\n",
        "    Returns:\n",
        "      A variable which is cast to fp16 if necessary.\n",
        "    \"\"\"\n",
        "\n",
        "    if dtype in CASTABLE_TYPES:\n",
        "      var = getter(name, shape, tf.float32, *args, **kwargs)\n",
        "      return tf.cast(var, dtype=dtype, name=name + '_cast')\n",
        "    else:\n",
        "      return getter(name, shape, dtype, *args, **kwargs)\n",
        "\n",
        "  def _model_variable_scope(self):\n",
        "    \"\"\"Returns a variable scope that the model should be created under.\n",
        "\n",
        "    If self.dtype is a castable type, model variable will be created in fp32\n",
        "    then cast to self.dtype before being used.\n",
        "\n",
        "    Returns:\n",
        "      A variable scope for the model.\n",
        "    \"\"\"\n",
        "\n",
        "    return tf.variable_scope('resnet_model',\n",
        "                             custom_getter=self._custom_dtype_getter)\n",
        "\n",
        "  def __call__(self, inputs, training):\n",
        "    \"\"\"Add operations to classify a batch of input images.\n",
        "\n",
        "    Args:\n",
        "      inputs: A Tensor representing a batch of input images.\n",
        "      training: A boolean. Set to True to add operations required only when\n",
        "        training the classifier.\n",
        "\n",
        "    Returns:\n",
        "      A logits Tensor with shape [<batch_size>, self.num_classes].\n",
        "    \"\"\"\n",
        "\n",
        "    with self._model_variable_scope():\n",
        "      #if self.data_format == 'channels_first':\n",
        "      #  # Convert the inputs from channels_last (NHWC) to channels_first (NCHW).\n",
        "      #  # This provides a large performance boost on GPU. See\n",
        "      #  # https://www.tensorflow.org/performance/performance_guide#data_formats\n",
        "      #  inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
        "\n",
        "      inputs = conv2d_fixed_padding(\n",
        "          inputs=inputs, filters=self.num_filters, kernel_size=self.kernel_size,\n",
        "          strides=self.conv_stride, data_format=self.data_format)\n",
        "      inputs = tf.identity(inputs, 'initial_conv')\n",
        "\n",
        "      # We do not include batch normalization or activation functions in V2\n",
        "      # for the initial conv1 because the first ResNet unit will perform these\n",
        "      # for both the shortcut and non-shortcut paths as part of the first\n",
        "      # block's projection. Cf. Appendix of [2].\n",
        "      if self.resnet_version == 1:\n",
        "        inputs = batch_norm(inputs, training, self.data_format, norm_type)\n",
        "        inputs = tf.nn.relu(inputs)\n",
        "\n",
        "      if self.first_pool_size:\n",
        "        inputs = tf.layers.max_pooling2d(\n",
        "            inputs=inputs, pool_size=self.first_pool_size,\n",
        "            strides=self.first_pool_stride, padding='SAME',\n",
        "            data_format=self.data_format)\n",
        "        inputs = tf.identity(inputs, 'initial_max_pool')\n",
        "        \n",
        "      outputs = {\n",
        "          'block0': inputs\n",
        "      }\n",
        "\n",
        "      for i, num_blocks in enumerate(self.block_sizes):\n",
        "        num_filters = self.num_filters * (2**i)\n",
        "        inputs = block_layer(\n",
        "            inputs=inputs, filters=num_filters, bottleneck=self.bottleneck,\n",
        "            block_fn=self.block_fn, blocks=num_blocks,\n",
        "            strides=self.block_strides[i], training=training,\n",
        "            name='block_layer{}'.format(i + 1), data_format=self.data_format, norm_type=self.norm_type)\n",
        "        \n",
        "        outputs['block{}'.format(i + 1)] = inputs\n",
        "\n",
        "      # Only apply the BN and ReLU for model that does pre_activation in each\n",
        "      # building/bottleneck block, eg resnet V2.\n",
        "      if self.pre_activation:\n",
        "        inputs = batch_norm(inputs, training, self.data_format, self.norm_type)\n",
        "        inputs = tf.nn.relu(inputs)\n",
        "\n",
        "      # The current top layer has shape\n",
        "      # `batch_size x pool_size x pool_size x final_size`.\n",
        "      # ResNet does an Average Pooling layer over pool_size,\n",
        "      # but that is the same as doing a reduce_mean. We do a reduce_mean\n",
        "      # here because it performs better than AveragePooling2D.\n",
        "      axes = [2, 3] if self.data_format == 'channels_first' else [1, 2]\n",
        "      outputs['final_feature_maps'] = (inputs, axes) \n",
        "    \n",
        "      if self.skip_reduction:\n",
        "        return outputs\n",
        "    \n",
        "      inputs = tf.reduce_mean(inputs, axes, keepdims=True)\n",
        "      inputs = tf.identity(inputs, 'final_reduce_mean')\n",
        "      outputs['reduce'] = inputs\n",
        "        \n",
        "      if self.skip_dense:\n",
        "        return outputs\n",
        "\n",
        "      inputs = tf.reshape(inputs, [-1, self.final_size])\n",
        "    \n",
        "      if not use_resnet_dense:\n",
        "        outputs['embeddings'] = inputs\n",
        "        return outputs\n",
        "      else:\n",
        "        #inputs = tf.layers.dense(inputs=inputs, units=self.num_classes)\n",
        "        resnet_dense = tf.layers.Dense(units=self.num_classes)\n",
        "        inputs = resnet_dense(inputs)\n",
        "        \n",
        "        tf.summary.histogram('embedding_dense_layer', resnet_dense.weights[0])\n",
        "        \n",
        "        inputs = tf.identity(inputs, 'final_dense')\n",
        "        outputs['embeddings'] = inputs\n",
        "        \n",
        "        return outputs\n",
        "      \n",
        "\n",
        "\n",
        "def get_block_sizes(resnet_size):\n",
        "  \"\"\"Retrieve the size of each block_layer in the ResNet model.\n",
        "  The number of block layers used for the Resnet model varies according\n",
        "  to the size of the model. This helper grabs the layer set we want, throwing\n",
        "  an error if a non-standard size has been selected.\n",
        "  Args:\n",
        "    resnet_size: The number of convolutional layers needed in the model.\n",
        "  Returns:\n",
        "    A list of block sizes to use in building the model.\n",
        "  Raises:\n",
        "    KeyError: if invalid resnet_size is received.\n",
        "  \"\"\"\n",
        "  choices = {\n",
        "      18: [2, 2, 2, 2],\n",
        "      34: [3, 4, 6, 3],\n",
        "      50: [3, 4, 6, 3],\n",
        "      101: [3, 4, 23, 3],\n",
        "      152: [3, 8, 36, 3],\n",
        "      200: [3, 24, 36, 3]\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    return choices[resnet_size]\n",
        "  except KeyError:\n",
        "    err = ('Could not find layers for selected Resnet size.\\n'\n",
        "           'Size received: {}; sizes allowed: {}.'.format(\n",
        "               resnet_size, choices.keys()))\n",
        "    raise ValueError(err)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2DkmZk4QMbT",
        "colab_type": "text"
      },
      "source": [
        "# MODEL ARCHITECTURE & MODEL_FN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdRxwai_pH9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RESNET MODEL\n",
        "resnet_model = None\n",
        "\n",
        "\"\"\"Define the model\"\"\"\n",
        "def model_fn(features, labels, mode):\n",
        "    \"\"\"Model function for tf.estimator\n",
        "    Args:\n",
        "        features: input batch of images\n",
        "        labels: labels of the images\n",
        "        mode: can be one of tf.estimator.ModeKeys.{TRAIN, EVAL, PREDICT}\n",
        "    Returns:\n",
        "        model_spec: tf.estimator.EstimatorSpec object\n",
        "    \"\"\"\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    images = features\n",
        "    images = tf.reshape(images, [-1, image_size, image_size, 3])\n",
        "    assert images.shape[1:] == [image_size, image_size, 3], \"{}\".format(images.shape)\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # MODEL: define the layers of the model\n",
        "    global resnet_model\n",
        "    if resnet_model == None:\n",
        "        resnet_model = Model(\n",
        "            resnet_size=50,\n",
        "            bottleneck=True,\n",
        "            num_classes=embedding_size,\n",
        "            num_filters=64,\n",
        "            kernel_size=7,\n",
        "            conv_stride=2,\n",
        "            first_pool_size=3,\n",
        "            first_pool_stride=2,\n",
        "            block_sizes=get_block_sizes(50),\n",
        "            block_strides=[1, 2, 2, 2],\n",
        "            final_size=2048,\n",
        "            resnet_version=2,\n",
        "            data_format= 'channels_last',#None,\n",
        "            skip_dense=False,\n",
        "            skip_reduction = False,\n",
        "            dtype=tf.float32\n",
        "        )\n",
        "    \n",
        "    #with tf.variable_scope('model'):\n",
        "        # Compute the embeddings with the model\n",
        "    embeddings = resnet_model(images, is_training)['embeddings']\n",
        "    \n",
        "    embedding_mean_norm = tf.reduce_mean(tf.norm(embeddings, axis=1))\n",
        "    tf.summary.scalar(\"embedding_mean_norm\", embedding_mean_norm)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        predictions = {'embeddings': embeddings}\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    labels = tf.cast(labels, tf.int64)\n",
        "    tf.summary.histogram('labels', labels)\n",
        "    \n",
        "    #emb_dist = pairwise_distance(tf.math.l2_normalize(embeddings, axis=1), squared=squared)\n",
        "    knn_accuracy, knn_mean_distance = tf_simple_KNN_score(tf.identity(embeddings), tf.identity(labels), is_training)\n",
        "    \n",
        "    if triplet_strategy == 'batch_all':\n",
        "        # BATCH ALL\n",
        "        loss, fraction = batch_all_triplet_loss(labels, embeddings, margin=margin,\n",
        "                                                squared=squared)\n",
        "    elif triplet_strategy == 'batch_all_semihard_tf':\n",
        "        # BATCH ALL SEMIHARD (TensorFlow loss)\n",
        "        loss, mean_num_positives = triplet_semihard_loss(labels, embeddings, margin)\n",
        "    else:\n",
        "        # BATCH HARD\n",
        "        loss = batch_hard_triplet_loss(labels, embeddings, margin=margin,\n",
        "                                       squared=squared)\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # METRICS AND SUMMARIES\n",
        "    # Metrics for evaluation using tf.metrics (average over whole dataset)\n",
        "    # TODO: some other metrics like rank-1 accuracy?\n",
        "    with tf.variable_scope(\"metrics\"):\n",
        "        eval_metric_ops = {\"embedding_mean_norm\": tf.metrics.mean(embedding_mean_norm),\n",
        "                          \"KNN_accuracy\": tf.metrics.mean(knn_accuracy),\n",
        "                          \"KNN_mean_dist\": tf.metrics.mean(knn_mean_distance)}\n",
        "        if triplet_strategy == 'batch_all':\n",
        "            eval_metric_ops['fraction_positive_triplets'] = tf.metrics.mean(fraction)\n",
        "        elif triplet_strategy == 'batch_all_semihard_tf':\n",
        "            eval_metric_ops[\"mean_num_positives\"] = tf.metrics.mean(mean_num_positives)\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        # Loss summary for validation set\n",
        "        #tf.summary.scalar('loss_val', loss)\n",
        "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
        "\n",
        "    \n",
        "    # Loss summary for train set\n",
        "    tf.summary.scalar('loss', loss)\n",
        "    \n",
        "    if triplet_strategy == 'batch_all_semihard_tf':\n",
        "        # Num_positives in batch_all_tf\n",
        "        tf.summary.scalar(\"mean_num_positives\", mean_num_positives)\n",
        "    \n",
        "    if triplet_strategy == 'batch_all':\n",
        "        tf.summary.scalar('fraction_positive_triplets', fraction)\n",
        "\n",
        "    tf.summary.image('train_image', images, max_outputs=1)\n",
        "\n",
        "    # Define training step that minimizes the loss with the Adam optimizer\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "    global_step = tf.train.get_global_step()\n",
        "    \n",
        "    # Add a dependency to update the moving mean and variance for batch normalization\n",
        "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
        "\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4m7KgxWQgaF",
        "colab_type": "text"
      },
      "source": [
        "# TRAIN AND EVALUATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HtYw_0bmV-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL INITIALIZATION AND TRAIN/EVALUATE\n",
        "\n",
        "tf.reset_default_graph()\n",
        "resnet_model = None\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "model_number += 1\n",
        "model_dir = models_folder+\"/model_\"+str(model_number)\n",
        "\n",
        "# Define the model\n",
        "tf.logging.info(\"Creating the model...\")\n",
        "\n",
        "config = tf.estimator.RunConfig(\n",
        "                            tf_random_seed=200,\n",
        "                            model_dir=model_dir,\n",
        "                            save_summary_steps=save_summary_steps,\n",
        "                            save_checkpoints_steps=save_checkpoints_steps)\n",
        "config = config.replace(keep_checkpoint_max=1)\n",
        "\n",
        "if make_warm_start:\n",
        "    vars_to_initialize = [\"^(?!.*(Adam|beta1_power|beta2_power|dense)).*$\"] if 'ImageNet' in warm_dir else [\"resnet_model.*\"]\n",
        "    ws = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=warm_dir, vars_to_warm_start=vars_to_initialize)\n",
        "    estimator = tf.estimator.Estimator(model_fn, config=config, warm_start_from=ws)\n",
        "else:\n",
        "    estimator = tf.estimator.Estimator(model_fn, config=config)\n",
        "\n",
        "# EVALUATION\n",
        "\n",
        "tf.logging.info(\"Evaluation on test set.\")\n",
        "res = estimator.evaluate(lambda: eval_input_fn(test_file))\n",
        "for key in res:\n",
        "    print(\"{}: {}\".format(key, res[key]))\n",
        "\n",
        "\n",
        "if (not make_warm_start) or (make_warm_start and train_after_warm_start):\n",
        "    # Train the model\n",
        "    tf.logging.info(\"Starting training for {} epoch(s).\".format(num_epochs))\n",
        "\n",
        "    # Set up an early stopping hook for the loss\n",
        "    if not os.path.exists(estimator.eval_dir()): os.makedirs(estimator.eval_dir())\n",
        "\n",
        "    early_stopping = tf.contrib.estimator.stop_if_no_decrease_hook(\n",
        "        estimator,\n",
        "        metric_name='loss',\n",
        "        max_steps_without_decrease=max_steps_without_decrease,\n",
        "        min_steps=10,\n",
        "        run_every_secs = None,\n",
        "        run_every_steps = run_every_steps)\n",
        "\n",
        "    # Train and Evaluate at the same time (producing checkpoints and evaluating for summary)\n",
        "    train_spec = tf.estimator.TrainSpec(input_fn=lambda: train_input_fn_batch_shuffling(train_files), hooks=[early_stopping])\n",
        "    eval_spec = tf.estimator.EvalSpec(input_fn=lambda: eval_input_fn(test_file), throttle_secs = min_secs_eval)\n",
        "    results = tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "    print(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRho03gJLZqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EVALUATION POST TRAINING\n",
        "\n",
        "tf.logging.info(\"Evaluation on test set.\")\n",
        "res = estimator.evaluate(lambda: eval_input_fn(test_file))\n",
        "for key in res:\n",
        "    print(\"{}: {}\".format(key, res[key]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kyyEME2Q8HC",
        "colab_type": "text"
      },
      "source": [
        "# PREDICT TEST-TRAIN & COMPUTE PAIRWISE DISTANCES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVJuxTb2QRyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD ALL THE IMAGES OF THE TEST SET TO USE IN KNN\n",
        "%reset_selective -f \"^test_images$\"\n",
        "test_images = []\n",
        "\n",
        "t = TFRecordExtractor(test_file)\n",
        "dataset = t.extract_image()\n",
        "\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_element = iterator.get_next()\n",
        "\n",
        "count = 0\n",
        "with tf.Session() as sess:\n",
        "    while True:\n",
        "        try:\n",
        "            sample = sess.run(next_element)\n",
        "            img = sample[0]\n",
        "            label = sample[1]\n",
        "            img = np.reshape(img, newshape= (img.shape[0], img.shape[1], 3) )\n",
        "            test_images.append( (img, label) )\n",
        "            count += 1\n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "            \n",
        "samples_for_scores = count\n",
        "test_images = np.array(test_images)\n",
        "print('Test images set:',test_images.shape)\n",
        "\n",
        "# LOAD ALL THE IMAGES OF THE TRAIN SET TO SHOW KNN\n",
        "%reset_selective -f \"^train_images$\"\n",
        "\n",
        "train_images = []\n",
        "\n",
        "t = TFRecordExtractor(train_file)\n",
        "dataset = t.extract_image()\n",
        "\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_element = iterator.get_next()\n",
        "\n",
        "count = 0\n",
        "with tf.Session() as sess:\n",
        "    while count < samples_for_scores:\n",
        "        try:\n",
        "            sample = sess.run(next_element)\n",
        "            img = sample[0]\n",
        "            label = sample[1]\n",
        "            img = np.reshape(img, newshape= (img.shape[0], img.shape[1], 3) )\n",
        "            train_images.append( (img, label) )\n",
        "            count += 1\n",
        "            \n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "            \n",
        "train_images = np.array(train_images)\n",
        "print('Train images set:',train_images.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZnxoKg4WmFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDICT THE TEST SET\n",
        "%reset_selective -f \"^test_embeddings$\"\n",
        "test_embeddings = list(estimator.predict(input_fn=lambda: load_knn_dataset(test_file), yield_single_examples=False))\n",
        "\n",
        "# GET THE TENSOR OF ALL THE EMBEDDINGS\n",
        "all_test_embeddings = None\n",
        "\n",
        "count = 0\n",
        "for elem in test_embeddings:\n",
        "    emb = elem['embeddings']\n",
        "    #print('Batch shape:',emb.shape)\n",
        "\n",
        "    all_test_embeddings = tf.concat([all_test_embeddings, emb], axis=0) if count > 0 else emb\n",
        "    count += emb.shape[0]\n",
        "    if count >= samples_for_scores: break\n",
        "    #print('Accumulated examples:',count)\n",
        "\n",
        "print('\\nTest prediction tensor shape:',all_test_embeddings.shape)\n",
        "\n",
        "# COMPUTE THE PAIRWISE DISTANCES BETWEEN ALL THE EMBEDDINGS\n",
        "test_emb_dist = tf.Session().run(pairwise_distance(all_test_embeddings, squared=squared))[:samples_for_scores, :samples_for_scores]\n",
        "print('Test distances tensor shape:', test_emb_dist.shape,'\\n')\n",
        "\n",
        "\n",
        "# PREDICT THE TRAIN SET\n",
        "%reset_selective -f \"^train_embeddings$\"\n",
        "train_embeddings = list(estimator.predict(input_fn=lambda: load_knn_dataset(train_file), yield_single_examples=False))\n",
        "\n",
        "# GET THE TENSOR OF ALL THE EMBEDDINGS\n",
        "all_train_embeddings = None\n",
        "\n",
        "count = 0\n",
        "for elem in train_embeddings:\n",
        "    emb = elem['embeddings']\n",
        "    #print('Batch shape:',emb.shape)\n",
        "\n",
        "    all_train_embeddings = tf.concat([all_train_embeddings, emb], axis=0) if count > 0 else emb\n",
        "    count += emb.shape[0]\n",
        "    if count >= samples_for_scores: break\n",
        "    #print('Accumulated examples:',count)\n",
        "\n",
        "print('\\nTrain prediction tensor shape:',all_train_embeddings.shape)\n",
        "\n",
        "# COMPUTE THE PAIRWISE DISTANCES BETWEEN ALL THE EMBEDDINGS\n",
        "train_emb_dist = tf.Session().run(pairwise_distance(all_train_embeddings, squared=squared))[:samples_for_scores, :samples_for_scores]\n",
        "print('Train distances tensor shape:', train_emb_dist.shape,'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQkOVlkhIk8P",
        "colab_type": "text"
      },
      "source": [
        "# KNN CALLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dyvNJB2RTK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_KNN(test_images, test_emb_dist, 9284, 2, 10, figsize=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZBx-R4PJsHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_KNN(train_images, train_emb_dist, 152711, 2, 10, figsize=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iywu_E3DuKcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "test_knn_score = simple_KNN_score(test_emb_dist, images_set=test_images, fracc=1.0)\n",
        "print(\"KNN test accuracy:\", 100*test_knn_score[0])\n",
        "print(\"Mean distance of all the most similar frames:\", test_knn_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r50xIZ9IzM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "train_knn_score = simple_KNN_score(train_emb_dist, images_set=train_images, fracc=1.0)\n",
        "print(\"KNN train accuracy:\", 100*train_knn_score[0])\n",
        "print(\"Mean distance of all the most similar frames:\",train_knn_score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMkfeyl2TRtI",
        "colab_type": "text"
      },
      "source": [
        "# RANK SCORE CALLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kCcoq5Bezwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "N = 2*label_frames_tolerance\n",
        "rank_scores = rank_score_upto_n(N, test_emb_dist, images_set=test_images, fracc=1.0)\n",
        "rank_scores = [score*100 for score in rank_scores]\n",
        "\n",
        "plt.bar(range(1, N+1), rank_scores)\n",
        "plt.plot()\n",
        "\n",
        "print(\"All test rank scores:\", rank_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC1fA5-vT4mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "N = 2*label_frames_tolerance\n",
        "rank_scores = rank_score_upto_n(N, train_emb_dist, images_set=train_images, fracc=1.0)\n",
        "rank_scores = [score*100 for score in rank_scores]\n",
        "\n",
        "plt.bar(range(1, N+1), rank_scores)\n",
        "plt.plot()\n",
        "\n",
        "print(\"All train rank scores:\", rank_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6S5__YmlY-M",
        "colab_type": "text"
      },
      "source": [
        "# K-MEANS CLUSTERING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBlZVDUD8K0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COMPUTE THE EMBEDDINGS ARRAY FOR THE ENTIRE TEST SET\n",
        "kmeans_test_embeddings = None\n",
        "\n",
        "count = 0\n",
        "for elem in test_embeddings:\n",
        "    emb = elem['embeddings']\n",
        "    #print('Batch shape:',emb.shape)\n",
        "\n",
        "    kmeans_test_embeddings = tf.concat([kmeans_test_embeddings, emb], axis=0) if count > 0 else emb\n",
        "    count += emb.shape[0]\n",
        "    #print('Accumulated examples:',count)\n",
        "\n",
        "print('Entire Test prediction tensor shape:',kmeans_test_embeddings.shape)\n",
        "\n",
        "# SAVE NUMPY ARRAY OF THE EMBEDDINGS FOR KMEANS CLUSTERING\n",
        "np_test_embeddings = tf.Session().run(kmeans_test_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Oa5p9RlYRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COMPUTE THE K-MEANS CLUSTERING FOR TEST EMBEDDINGS\n",
        "def compute_clusters(num_clusters):\n",
        "    assert num_clusters <= 8, 'Maximum number of clusters able to visualize is 8'\n",
        "    kmeans_test = KMeans(num_clusters, random_state=0).fit(np_test_embeddings)\n",
        "    return kmeans_test.labels_, kmeans_test.cluster_centers_\n",
        "\n",
        "def compute_clusters_with_centroids(num_clusters, centroids):\n",
        "    assert num_clusters <= 8, 'Maximum number of clusters able to visualize is 8'\n",
        "    assert centroids.shape == (num_clusters, embedding_size), 'Centroids provided have wrong shape: '+str(centroids.shape)\n",
        "    kmeans_test = KMeans(num_clusters, init=centroids, n_init=1, random_state=0).fit(np_test_embeddings)\n",
        "    return kmeans_test.labels_, kmeans_test.cluster_centers_\n",
        "\n",
        "def cluster_to_color(cluster_label):\n",
        "    if cluster_label == 0: return 'red'\n",
        "    elif cluster_label == 1: return 'green'\n",
        "    elif cluster_label == 2: return 'blue'\n",
        "    elif cluster_label == 3: return 'c'\n",
        "    elif cluster_label == 4: return 'm'\n",
        "    elif cluster_label == 5: return 'y'\n",
        "    elif cluster_label == 6: return 'k'\n",
        "    elif cluster_label == 7: return 'w'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByXY8Y7Jnowv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# VISUALIZE THE CLUSTERS\n",
        "for n in range(2,4):\n",
        "    test_clusters_labels = compute_clusters(n)[0]\n",
        "    x = 0\n",
        "    for label in test_clusters_labels:\n",
        "        plt.plot([x, x], [0, 1], color=cluster_to_color(label))\n",
        "        x += 1\n",
        "    print('Test clusters by colour with',n,'clusters')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmUzJaQa5CvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# CLUSTERING WITH SELECTED CENTROIDS\n",
        "selected_centroids_2 = np.array( [np_test_embeddings[500], np_test_embeddings[2000]] )\n",
        "selected_clusters_labels_2 = compute_clusters_with_centroids(2, selected_centroids_2)[0]\n",
        "\n",
        "x = 0\n",
        "for label in selected_clusters_labels_2:\n",
        "    plt.plot([x, x], [0, 1], color=cluster_to_color(label))\n",
        "    x += 1\n",
        "print('Test clusters with selected centroids by colour with',2,'clusters')\n",
        "plt.show()\n",
        "\n",
        "selected_centroids_3 = np.array( [np_test_embeddings[500], np_test_embeddings[900], np_test_embeddings[2000]] )\n",
        "selected_clusters_labels_3 = compute_clusters_with_centroids(3, selected_centroids_3)[0]\n",
        "\n",
        "x = 0\n",
        "for label in selected_clusters_labels_3:\n",
        "    plt.plot([x, x], [0, 1], color=cluster_to_color(label))\n",
        "    x += 1\n",
        "print('Test clusters with selected centroids by colour with',3,'clusters')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# CLUSTERING WITH MEAN CENTROIDS\n",
        "mean_centroids = np.array( [np.mean(np_test_embeddings[:999], axis=0), np.mean(np_test_embeddings[1000:-1], axis=0)] )\n",
        "mean_clusters_labels = compute_clusters_with_centroids(2, mean_centroids)[0]\n",
        "\n",
        "x = 0\n",
        "for label in mean_clusters_labels:\n",
        "    plt.plot([x, x], [0, 1], color=cluster_to_color(label))\n",
        "    x += 1\n",
        "print('Test clusters with mean centroids by colour with',2,'clusters')\n",
        "plt.show()\n",
        "\n",
        "mean_centroids = np.array( [np.mean(np_test_embeddings[:799], axis=0), np.mean(np_test_embeddings[800:999], axis=0), np.mean(np_test_embeddings[1000:-1], axis=0)] )\n",
        "mean_clusters_labels = compute_clusters_with_centroids(3, mean_centroids)[0]\n",
        "\n",
        "x = 0\n",
        "for label in mean_clusters_labels:\n",
        "    plt.plot([x, x], [0, 1], color=cluster_to_color(label))\n",
        "    x += 1\n",
        "print('Test clusters with mean centroids by colour with',3,'clusters')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM8aUz4XrEW0",
        "colab_type": "text"
      },
      "source": [
        "# CLUSTER IMAGES (CENTROIDS SELECTED)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWsSB3TqrHnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2 CLUSTER IMAGES\n",
        "cl1 = test_images[ np.where(selected_clusters_labels_2==0), 0][0]\n",
        "cl2 = test_images[ np.where(selected_clusters_labels_2==1), 0][0]\n",
        "\n",
        "mean_cl1 = np.mean(cl1)\n",
        "mean_cl2 = np.mean(cl2)\n",
        "\n",
        "f, axarr = plt.subplots(ncols=2, nrows=2, figsize=(10, 7))\n",
        "axarr[0,0].imshow(test_images[500, 0])\n",
        "axarr[0,0].set_title('Selected centroid num 1')\n",
        "axarr[0,1].imshow(mean_cl1)\n",
        "axarr[0,1].set_title('Mean image for cluster 1')\n",
        "axarr[1,0].imshow(test_images[2000, 0])\n",
        "axarr[1,0].set_title('Selected centroid num 2')\n",
        "axarr[1,1].imshow(mean_cl2)\n",
        "axarr[1,1].set_title('Mean image for cluster 2')\n",
        "\n",
        "print('Mean cluster image using all images in each cluster (2 clusters)')\n",
        "plt.show()\n",
        "\n",
        "# PLOT N RANDOM IMAGES FROM EACH CLUSTER\n",
        "n = 20 # MUST BE MULTIPLE OF 10 AND 2 FOR PROPER VISUALIZATION\n",
        "cl1_samples = np.random.choice(cl1, n)\n",
        "cl2_samples = np.random.choice(cl2, n)\n",
        "\n",
        "f, axarr = plt.subplots(ncols=int(n/2), nrows=int(n/10), figsize=(25, 5))\n",
        "j = 0\n",
        "for i in range(n):\n",
        "    axarr[j, i%int(n/2)].imshow(cl1_samples[i])\n",
        "    if (i+1) % int(n/2) == 0: j += 1\n",
        "print(n,'random images from cluster 1')\n",
        "plt.show()\n",
        "\n",
        "f, axarr = plt.subplots(ncols=int(n/2), nrows=int(n/10), figsize=(25, 5))\n",
        "j = 0\n",
        "for i in range(n):\n",
        "    axarr[j, i%int(n/2)].imshow(cl2_samples[i])\n",
        "    if (i+1) % int(n/2) == 0: j += 1\n",
        "print(n,'random images from cluster 2')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ibrVzH8wAGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3 CLUSTER IMAGES\n",
        "cl1 = test_images[ np.where(selected_clusters_labels_3==0), 0][0]\n",
        "cl2 = test_images[ np.where(selected_clusters_labels_3==1), 0][0]\n",
        "cl3 = test_images[ np.where(selected_clusters_labels_3==2), 0][0]\n",
        "\n",
        "mean_cl1 = np.mean(cl1)\n",
        "mean_cl2 = np.mean(cl2)\n",
        "mean_cl3 = np.mean(cl3)\n",
        "\n",
        "f, axarr = plt.subplots(ncols=2, nrows=3, figsize=(15, 10))\n",
        "axarr[0,0].imshow(test_images[200, 0])\n",
        "axarr[0,0].set_title('Selected centroid num 1')\n",
        "axarr[0,1].imshow(mean_cl1)\n",
        "axarr[0,1].set_title('Mean image for cluster 1')\n",
        "axarr[1,0].imshow(test_images[850, 0])\n",
        "axarr[1,0].set_title('Selected centroid num 2')\n",
        "axarr[1,1].imshow(mean_cl2)\n",
        "axarr[1,1].set_title('Mean image for cluster 2')\n",
        "axarr[2,0].imshow(test_images[1500, 0])\n",
        "axarr[2,0].set_title('Selected centroid num 3')\n",
        "axarr[2,1].imshow(mean_cl3)\n",
        "axarr[2,1].set_title('Mean image for cluster 3')\n",
        "\n",
        "print('Mean cluster image using all images in each cluster (3 clusters)')\n",
        "plt.show()\n",
        "\n",
        "# PLOT N RANDOM IMAGES FROM EACH CLUSTER\n",
        "n = 20 # MUST BE MULTIPLE OF 10 AND 2 FOR PROPER VISUALIZATION\n",
        "cl1_samples = np.random.choice(cl1, n)\n",
        "cl2_samples = np.random.choice(cl2, n)\n",
        "cl3_samples = np.random.choice(cl3, n)\n",
        "\n",
        "f, axarr = plt.subplots(ncols=int(n/2), nrows=int(n/10), figsize=(25, 5))\n",
        "j = 0\n",
        "for i in range(n):\n",
        "    axarr[j, i%int(n/2)].imshow(cl1_samples[i])\n",
        "    if (i+1) % int(n/2) == 0: j += 1\n",
        "print(n,'random images from cluster 1')\n",
        "plt.show()\n",
        "\n",
        "f, axarr = plt.subplots(ncols=int(n/2), nrows=int(n/10), figsize=(25, 5))\n",
        "j = 0\n",
        "for i in range(n):\n",
        "    axarr[j, i%int(n/2)].imshow(cl2_samples[i])\n",
        "    if (i+1) % int(n/2) == 0: j += 1\n",
        "print(n,'random images from cluster 2')\n",
        "plt.show()\n",
        "\n",
        "f, axarr = plt.subplots(ncols=int(n/2), nrows=int(n/10), figsize=(25, 5))\n",
        "j = 0\n",
        "for i in range(n):\n",
        "    axarr[j, i%int(n/2)].imshow(cl3_samples[i])\n",
        "    if (i+1) % int(n/2) == 0: j += 1\n",
        "print(n,'random images from cluster 3')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKtYGguEEK_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "centers = 10\n",
        "kmeans_multiple_centers = KMeans(centers, random_state=0).fit(np_test_embeddings).labels_\n",
        "\n",
        "n = 20 # MUST BE MULTIPLE OF 10 AND 2 FOR PROPER VISUALIZATION\n",
        "\n",
        "clusters = [ test_images[ np.where(kmeans_multiple_centers==i), 0][0] for i in range(centers) ]\n",
        "clusters_samples = [ np.random.choice(cl, n) for cl in clusters]\n",
        "\n",
        "for k in range(len(clusters_samples)):\n",
        "    samples = clusters_samples[k]\n",
        "    \n",
        "    f, axarr = plt.subplots(ncols=int(n/2), nrows=int(n/10), figsize=(25, 5))\n",
        "    j = 0\n",
        "    for i in range(n):\n",
        "        axarr[j, i%int(n/2)].imshow(samples[i])\n",
        "        if (i+1) % int(n/2) == 0: j += 1\n",
        "    print(n,'random images from cluster', k+1)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvy-lRG08LNT",
        "colab_type": "text"
      },
      "source": [
        "# UMAP CLUSTERING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOFViPpK8NYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "colors = np.array( list(range(np_test_embeddings.shape[0])) )\n",
        "colors = colors - colors.min()\n",
        "colors = colors / colors.max()\n",
        "\n",
        "\n",
        "label_color_map = lambda x: 'r' if x<=600 else 'g' if x <= 1000 else 'b'\n",
        "label_color = [label_color_map(l) for l in range(np_test_embeddings.shape[0])]\n",
        "\n",
        "umap2d_embedding = umap.UMAP(random_state=42).fit_transform(np_test_embeddings)\n",
        "\n",
        "f, axarr = plt.subplots(ncols=1, nrows=1, figsize=(18, 15))\n",
        "axarr.set_title('2D UMAP clustering')\n",
        "#axarr.scatter(umap2d_embedding[:, 0], umap2d_embedding[:, 1], c=colors, s=10, cmap='magma')\n",
        "axarr.scatter(umap2d_embedding[:, 0], umap2d_embedding[:, 1], c=label_color, s=10)\n",
        "plt.show()\n",
        "\n",
        "umap3d_embedding = umap.UMAP(random_state=42, n_components=3).fit_transform(np_test_embeddings)\n",
        "\n",
        "fig = plt.figure(figsize=(18,15))\n",
        "ax = Axes3D(fig)\n",
        "ax.scatter(umap3d_embedding[:, 0], umap3d_embedding[:, 1], umap3d_embedding[:, 2], c=label_color, s=10)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjP4DTWXRbQb",
        "colab_type": "text"
      },
      "source": [
        "# KNN BEFORE CLASSIFICATION TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olMlIDezRf-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classification_samples_for_scores = 2952\n",
        "train_classification_samples_for_scores = 3202\n",
        "\n",
        "# LOAD ALL THE IMAGES OF THE TEST SET\n",
        "%reset_selective -f \"^classification_test_images$\"\n",
        "classification_test_images = []\n",
        "\n",
        "t = TFRecordExtractor(gfl_classification_test)\n",
        "dataset = t.extract_image()\n",
        "\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_element = iterator.get_next()\n",
        "\n",
        "count = 0\n",
        "with tf.Session() as sess:\n",
        "    while count < classification_samples_for_scores:\n",
        "        try:\n",
        "            sample = sess.run(next_element)\n",
        "            img = sample[0]\n",
        "            label = sample[1]\n",
        "            img = np.reshape(img, newshape= (img.shape[0], img.shape[1], 3) )\n",
        "            classification_test_images.append( (img, label) )\n",
        "            count += 1\n",
        "            \n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "            \n",
        "classification_test_images = np.array(classification_test_images)\n",
        "print('Test images set:',classification_test_images.shape)\n",
        "\n",
        "# LOAD ALL THE IMAGES OF THE TRAIN SET\n",
        "%reset_selective -f \"^classification_train_images$\"\n",
        "classification_train_images = []\n",
        "\n",
        "t = TFRecordExtractor(gfl_classification_train)\n",
        "dataset = t.extract_image()\n",
        "\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_element = iterator.get_next()\n",
        "\n",
        "count = 0\n",
        "with tf.Session() as sess:\n",
        "    while count < train_classification_samples_for_scores:\n",
        "        try:\n",
        "            sample = sess.run(next_element)\n",
        "            img = sample[0]\n",
        "            label = sample[1]\n",
        "            img = np.reshape(img, newshape= (img.shape[0], img.shape[1], 3) )\n",
        "            classification_train_images.append( (img, label) )\n",
        "            count += 1\n",
        "            \n",
        "        except tf.errors.OutOfRangeError:\n",
        "            break\n",
        "            \n",
        "classification_train_images = np.array(classification_train_images)\n",
        "print('Train images set:',classification_train_images.shape)\n",
        "\n",
        "# PREDICT THE TEST SET\n",
        "%reset_selective -f \"^classification_test_embeddings$\"\n",
        "classification_test_embeddings = list(estimator.predict(input_fn=lambda: load_knn_dataset(gfl_classification_test), yield_single_examples=False))\n",
        "\n",
        "# GET THE TENSOR OF ALL THE EMBEDDINGS\n",
        "all_classification_test_embeddings = None\n",
        "\n",
        "count = 0\n",
        "for elem in classification_test_embeddings:\n",
        "    emb = elem['embeddings']\n",
        "    #print('Batch shape:',emb.shape)\n",
        "\n",
        "    all_classification_test_embeddings = tf.concat([all_classification_test_embeddings, emb], axis=0) if count > 0 else emb\n",
        "    count += 1\n",
        "    if count >= classification_samples_for_scores: break\n",
        "    #print('Accumulated examples:',count)\n",
        "\n",
        "print('Test prediction tensor shape:',all_classification_test_embeddings.shape)\n",
        "\n",
        "# COMPUTE THE PAIRWISE DISTANCES BETWEEN ALL THE EMBEDDINGS\n",
        "classification_test_emb_dist = tf.Session().run(pairwise_distance(all_classification_test_embeddings, squared=squared))[:classification_samples_for_scores, :classification_samples_for_scores]\n",
        "print('Test distances tensor shape:', classification_test_emb_dist.shape,'\\n')\n",
        "\n",
        "\n",
        "# PREDICT THE TRAIN SET\n",
        "%reset_selective -f \"^classification_train_embeddings$\"\n",
        "classification_train_embeddings = list(estimator.predict(input_fn=lambda: load_knn_dataset(gfl_classification_train), yield_single_examples=False))\n",
        "\n",
        "# GET THE TENSOR OF ALL THE EMBEDDINGS\n",
        "all_classification_train_embeddings = None\n",
        "\n",
        "count = 0\n",
        "for elem in classification_train_embeddings:\n",
        "    emb = elem['embeddings']\n",
        "    #print('Batch shape:',emb.shape)\n",
        "\n",
        "    all_classification_train_embeddings = tf.concat([all_classification_train_embeddings, emb], axis=0) if count > 0 else emb\n",
        "    count += 1\n",
        "    if count >= train_classification_samples_for_scores: break\n",
        "    #print('Accumulated examples:',count)\n",
        "\n",
        "\n",
        "print('Train prediction tensor shape:',all_classification_train_embeddings.shape)\n",
        "\n",
        "# COMPUTE THE PAIRWISE DISTANCES BETWEEN ALL THE EMBEDDINGS\n",
        "classification_train_emb_dist = tf.Session().run(pairwise_distance(all_classification_train_embeddings, squared=squared))[:train_classification_samples_for_scores, :train_classification_samples_for_scores]\n",
        "print('Train distances tensor shape:', classification_train_emb_dist.shape,'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61r__F5jR5_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_KNN(classification_test_images, classification_test_emb_dist, -1, 2, 10, figsize=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaF8xvw0aXJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_KNN(classification_train_images, classification_train_emb_dist, -1, 2, 10, figsize=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "313jmsOJT7k-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classification_rank_n_score(emb_dist, n, all_images):\n",
        "    all_labels = all_images[:, 1]\n",
        "    counts = [0]*(np.max(all_labels) + 1)\n",
        "    for i in range(len(all_labels)):\n",
        "        label = all_labels[i]\n",
        "        distances = emb_dist[i, :]\n",
        "        \n",
        "        index = np.argsort(distances)[1:n+1] # taking the next closest that is not itself\n",
        "        #print(label, all_labels[index], index, distances)\n",
        "        if label in all_labels[index]: counts[label] += 1\n",
        "        \n",
        "    return np.array( counts )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2eMG6UAXlEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rank = 1\n",
        "rank_1_test = classification_rank_n_score(classification_test_emb_dist, 1, classification_test_images)\n",
        "print('Test Rank 1 score prior to classification training')\n",
        "print('Correct number of classifications per class:', rank_1_test)\n",
        "print('% correct classifications:', np.sum(rank_1_test)*100/classification_samples_for_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUQM7skbaIgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rank = 1\n",
        "rank_1_train = classification_rank_n_score(classification_train_emb_dist, 1, classification_train_images)\n",
        "print('Train Rank 1 score prior to classification training')\n",
        "print('Correct number of classifications per class:', rank_1_train)\n",
        "print('% correct classifications:', np.sum(rank_1_train)*100/train_classification_samples_for_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBWw0aJ6Og2o",
        "colab_type": "text"
      },
      "source": [
        "# CLASSIFICATION TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQyjwDcyIPkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLASSIFICATION PARAMS\n",
        "learning_rate = 1e-2\n",
        "num_classes = 7\n",
        "classification_num_epochs = -1 # 600 used in the first approach!\n",
        "classification_batch_size = 64\n",
        "classification_data_augmentation = True\n",
        "log_every_steps = 200\n",
        "\n",
        "classification_warm_start = True\n",
        "classification_warm_dir = 'resnet50_ImageNet'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_MmYzArOji1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Define the model for classification\"\"\"\n",
        "def classifier_model_fn(features, labels, mode):\n",
        "    \"\"\"Model function for tf.estimator\n",
        "    Args:\n",
        "        features: input batch of images\n",
        "        labels: labels of the images\n",
        "        mode: can be one of tf.estimator.ModeKeys.{TRAIN, EVAL, PREDICT}\n",
        "    Returns:\n",
        "        model_spec: tf.estimator.EstimatorSpec object\n",
        "    \"\"\"\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    images = features\n",
        "    images = tf.reshape(images, [-1, image_size, image_size, 3])\n",
        "    assert images.shape[1:] == [image_size, image_size, 3], \"{}\".format(images.shape)\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    # MODEL: define the layers of the model\n",
        "    global resnet_model\n",
        "    if resnet_model == None:\n",
        "        resnet_model = Model(\n",
        "            resnet_size=50,\n",
        "            bottleneck=True,\n",
        "            num_classes=embedding_size,\n",
        "            num_filters=64,\n",
        "            kernel_size=7,\n",
        "            conv_stride=2,\n",
        "            first_pool_size=3,\n",
        "            first_pool_stride=2,\n",
        "            block_sizes=get_block_sizes(50),\n",
        "            block_strides=[1, 2, 2, 2],\n",
        "            final_size=2048,\n",
        "            resnet_version=2,\n",
        "            data_format='channels_last',\n",
        "            skip_dense=False,\n",
        "            skip_reduction = False,\n",
        "            dtype=tf.float32\n",
        "        )\n",
        "    \n",
        "    #with tf.variable_scope('model'):\n",
        "        # Compute the embeddings with the model\n",
        "    embeddings = resnet_model(images, False)['embeddings']\n",
        "    with tf.variable_scope('trainable_classification'):\n",
        "        dense_layer = tf.layers.Dense(num_classes, activation=None, name='classification_dense_layer')\n",
        "        logits = dense_layer(embeddings)\n",
        "        tf.summary.histogram('classification_dense_layer', dense_layer.weights[0])\n",
        "    \n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        probabilities = tf.nn.softmax(logits)\n",
        "        predictions = {'probabilities': probabilities}\n",
        "        #predictions = {'embeddings': embeddings}\n",
        "        \n",
        "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "    labels = tf.cast(labels, tf.int64)\n",
        "    predicted_logit = tf.argmax(input=logits, axis=1, \n",
        "                                output_type=tf.int32)\n",
        "    \n",
        "    cross_entropy = tf.losses.sparse_softmax_cross_entropy(\n",
        "        labels=labels, logits=logits, scope='loss')\n",
        "\n",
        "    #with tf.name_scope('accuracy'):\n",
        "    accuracy = ( tf.metrics.accuracy(\n",
        "        labels=labels, predictions=predicted_logit, name='acc') )\n",
        "        \n",
        "    tf.summary.scalar('accuracy', accuracy[1])\n",
        "    tf.summary.scalar('loss', cross_entropy)\n",
        "    \n",
        "    embedding_mean_norm = tf.reduce_mean(tf.norm(embeddings, axis=1))\n",
        "    logit_mean_norm = tf.reduce_mean(tf.norm(logits, axis=1))\n",
        "    predicted_mean = tf.reduce_mean(tf.cast(predicted_logit, tf.float32))\n",
        "    labels_mean = tf.reduce_mean(tf.cast(labels, tf.float32))\n",
        "    \n",
        "    if mode == tf.estimator.ModeKeys.EVAL:\n",
        "        return tf.estimator.EstimatorSpec(mode, loss=cross_entropy, eval_metric_ops={\n",
        "            'accuracy':accuracy,\n",
        "            'embedding_mean_norm':tf.metrics.mean(embedding_mean_norm),\n",
        "            'logit_mean_norm':tf.metrics.mean(logit_mean_norm),\n",
        "            'predicted_mean':tf.metrics.mean(predicted_mean),\n",
        "            'labels_mean':tf.metrics.mean(labels_mean)\n",
        "        } )\n",
        "    \n",
        "    \n",
        "    # Only train last Dense layer\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "    global_step = tf.train.get_global_step()\n",
        "    classification_train_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'trainable_classification')\n",
        "    train_op = optimizer.minimize(cross_entropy, global_step, var_list=classification_train_variables)\n",
        "    #train_op = optimizer.minimize(cross_entropy, global_step)\n",
        "    \n",
        "    \n",
        "    # Create a hook to print acc, loss & global step  \n",
        "    train_hook_list= []\n",
        "    train_tensors_log = {'accuracy': accuracy[1],\n",
        "                         'loss': cross_entropy,\n",
        "                         'embedding_mean_norm':embedding_mean_norm,\n",
        "                         'logit_mean_norm':logit_mean_norm,\n",
        "                         'predicted_mean':predicted_mean,\n",
        "                         'labels_mean':labels_mean,\n",
        "                         'global_step': global_step}\n",
        "    train_hook_list.append(tf.train.LoggingTensorHook(\n",
        "        tensors=train_tensors_log, every_n_iter=log_every_steps))\n",
        "\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=cross_entropy, train_op=train_op, training_hooks=train_hook_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_hHTbqZJwUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classification_train_input_fn(filename):\n",
        "    dataset = load_dataset(filename)\n",
        "    if classification_data_augmentation:\n",
        "        dataset = apply_data_augmentations(dataset)\n",
        "    dataset = dataset.shuffle(buffer_size=250)\n",
        "    dataset = dataset.batch(classification_batch_size)\n",
        "    if classification_num_epochs >= 0: dataset = dataset.repeat(classification_num_epochs)\n",
        "    else: dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(1)\n",
        "    return dataset\n",
        "\n",
        "def classification_test_input_fn(filename):\n",
        "    dataset = load_dataset(filename)\n",
        "    dataset = dataset.batch(classification_batch_size)\n",
        "    dataset = dataset.prefetch(1)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y21Grd86m_r-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "\n",
        "tf.reset_default_graph()\n",
        "resnet_model = None\n",
        "\n",
        "tf.logging.info(\"Creating the model...\")\n",
        "classifier_model_dir = models_folder+\"/model_\"+str(model_number)+\"_c\"\n",
        "config = tf.estimator.RunConfig(\n",
        "                                tf_random_seed=200,\n",
        "                                model_dir=classifier_model_dir,\n",
        "                                save_summary_steps=save_summary_steps,\n",
        "                                save_checkpoints_steps=save_checkpoints_steps)\n",
        "config = config.replace(keep_checkpoint_max=1)\n",
        "\n",
        "'''\n",
        "vars_to_initialize = [\"^(?!.*(Adam|beta1_power|beta2_power|trainable)).*$\"] if 'ImageNet' in warm_dir else [\"model\\/.*\"]\n",
        "ws = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=warm_dir, vars_to_warm_start=vars_to_initialize)\n",
        "estimator = tf.estimator.Estimator(classifier_model_fn, config=config, warm_start_from=ws)\n",
        "'''\n",
        "\n",
        "classification_warm_from = classification_warm_dir if classification_warm_start else model_dir\n",
        "ws = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=classification_warm_from, vars_to_warm_start=[\"resnet_model.*\"])\n",
        "estimator = tf.estimator.Estimator(classifier_model_fn, config=config, warm_start_from=ws)\n",
        "\n",
        "# EVALUATION PRE TRAINING\n",
        "tf.logging.info(\"Evaluation on test set.\")\n",
        "res = estimator.evaluate(lambda: classification_test_input_fn(gfl_classification_test))\n",
        "for key in res:\n",
        "    print(\"{}: {}\".format(key, res[key]))\n",
        "\n",
        "\n",
        "# Train the model\n",
        "tf.logging.info(\"Starting training for {} epoch(s).\".format(classification_num_epochs))\n",
        "\n",
        "# Set up an early stopping hook for the loss\n",
        "if not os.path.exists(estimator.eval_dir()): os.makedirs(estimator.eval_dir())\n",
        "\n",
        "# Train and Evaluate at the same time (producing checkpoints and evaluating for summary)\n",
        "train_spec = tf.estimator.TrainSpec(input_fn=lambda: classification_train_input_fn(gfl_classification_train), hooks=[])\n",
        "eval_spec = tf.estimator.EvalSpec(input_fn=lambda: classification_test_input_fn(gfl_classification_test), throttle_secs = min_secs_eval)\n",
        "results = tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Uzkrr8Nrd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EVALUATION POST TRAINING\n",
        "\n",
        "tf.logging.info(\"Evaluation on test set.\")\n",
        "res = estimator.evaluate(lambda: classification_test_input_fn(gfl_classification_train))\n",
        "for key in res:\n",
        "    print(\"{}: {}\".format(key, res[key]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgRrtk2-br73",
        "colab_type": "text"
      },
      "source": [
        "# CLASSIFICATION EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2MoZ_yGcGCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PREDICT THE TEST SET\n",
        "%reset_selective -f \"^test_probabilities$\"\n",
        "test_probabilities = np.array( [x['probabilities'] for x in list(estimator.predict(input_fn=lambda: load_dataset(gfl_classification_test), yield_single_examples=False))] )\n",
        "\n",
        "print('\\nTest prediction tensor shape:',test_probabilities.shape)\n",
        "\n",
        "\n",
        "# PREDICT THE TRAIN SET\n",
        "%reset_selective -f \"^train_probabilities$\"\n",
        "train_probabilities = np.array( [x['probabilities'] for x in list(estimator.predict(input_fn=lambda: load_dataset(gfl_classification_train), yield_single_examples=False))] )\n",
        "\n",
        "print('\\nTrain prediction tensor shape:',train_probabilities.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUcD6r52Qart",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_probabilities = np.reshape(test_probabilities, newshape=(classification_samples_for_scores, num_classes))\n",
        "train_probabilities = np.reshape(train_probabilities, newshape=(train_classification_samples_for_scores, num_classes))\n",
        "print('Train probabilities shape:', train_probabilities.shape)\n",
        "print('Test probabilities shape:', test_probabilities.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cPfL8NIcrGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "test_images_per_class = [400, 500, 52, 500, 500, 500, 500]\n",
        "\n",
        "y_pred_test = []\n",
        "y_true_test = []\n",
        "\n",
        "# Visualize probabilities for each test image\n",
        "\n",
        "count = 0\n",
        "for i in range(num_classes):\n",
        "    sum_probs = None\n",
        "    num_images = test_images_per_class[i]\n",
        "    print('Test images class', i)\n",
        "    print('Num test images for this class:', num_images)\n",
        "    for n in range(num_images):\n",
        "        index = count\n",
        "        img, label = classification_test_images[index]\n",
        "        probs = test_probabilities[index]\n",
        "        y_pred_test.append(probs.argmax())\n",
        "        y_true_test.append(label)\n",
        "        sum_probs = sum_probs + probs if sum_probs is not None else probs\n",
        "        count += 1\n",
        "    \n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    c = ['blue']*num_classes\n",
        "    c[i] = 'red'\n",
        "    plt.bar(range(num_classes) ,sum_probs, color=c)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K4-YYfAdnJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_per_class = [400, 500, 302, 500, 500, 500, 500]\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Visualize probabilities for each train image\n",
        "\n",
        "count = 0\n",
        "for i in range(num_classes):\n",
        "    sum_probs = None\n",
        "    num_images = train_images_per_class[i]\n",
        "    print('Train images class', i)\n",
        "    print('Num train images for this class:', num_images)\n",
        "    \n",
        "    for n in range(num_images):\n",
        "        index = count\n",
        "        \n",
        "        img, label = classification_train_images[index]\n",
        "        probs = train_probabilities[index]\n",
        "        y_pred.append(probs.argmax())\n",
        "        y_true.append(label)\n",
        "        sum_probs = sum_probs + probs if sum_probs is not None else probs\n",
        "        count += 1\n",
        "    \n",
        "    print('Label:', label)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    c = ['blue']*num_classes\n",
        "    c[i] = 'red'\n",
        "    plt.bar(range(num_classes) ,sum_probs, color=c)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlOJGPUOhlJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf_train = confusion_matrix(y_true,y_pred)\n",
        "conf_test = confusion_matrix(y_true_test,y_pred_test)\n",
        "train_corrects = np.diag(conf_train)\n",
        "test_corrects = np.diag(conf_test)\n",
        "\n",
        "print('Train confusion matrix')\n",
        "print(conf_train)\n",
        "print('\\nTrain corrects per class:', train_corrects)\n",
        "print('% correct classifications:', np.sum(train_corrects)*100/train_classification_samples_for_scores)\n",
        "\n",
        "\n",
        "print('\\nTest confusion matrix')\n",
        "print(conf_test)\n",
        "print('\\nTest corrects per class:', test_corrects)\n",
        "print('% correct classifications:', np.sum(test_corrects)*100/classification_samples_for_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3otxIBYnVelr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}